[{"path":"index.html","id":"preface","chapter":"Preface","heading":"Preface","text":"","code":""},{"path":"index.html","id":"online-teaching","chapter":"Preface","heading":"Online teaching","text":"\ncorona virus pandemic impacts lives changes way teach learn. course held online. Please patient activities turn successful technical tools function desired. best support curriculum.\ncourse, use following tools:ILIAS: moodle platform UoC. registered already.Campuswire: chat platform decrease number emails allow natural exchange participants lecturer. received invitation email, , send email, please.Zoom: used live presentations. Please check registration requirements ILIAS.RStudio Server Pro: server running R RStudio installation. working .","code":""},{"path":"index.html","id":"intended-learning-outcomes-ilos","chapter":"Preface","heading":"Intended learning outcomes (ILOs)","text":"end course able \nWrite simple R scripts data analysis.\n\nExplain statistical methods learnt course.\n\nApply statistical methods learnt course.\n\nApply selected methods new data set write report.\n","code":""},{"path":"index.html","id":"literature","chapter":"Preface","heading":"Literature","text":"using book ModernDive: Statistical Inference via Data Science (Ismay Kim 2021) mainly. Additionally, recommend time time R Data Science (Wickham Grolemund 2021) OpenIntro Statistics (Diez, √áetinkaya-Rundel, Barr 2019). report, additional literature search depending topic.","code":""},{"path":"index.html","id":"why-these-lecture-notes","chapter":"Preface","heading":"Why these lecture notes","text":"document working live document updated course. comprehensive, help navigate introduction R statistics smoothly.use different colour boxes\nInfos tips\n\nLearning outcomes\n\nimportant\n\ndefinition\n\nexercise inside chapter.\n","code":""},{"path":"index.html","id":"acknowledgements","chapter":"Preface","heading":"Acknowledgements","text":"document based free material provided byModernDive: Ismay Kim (2021) free Problem Sets authored Jenny Smetzer, William Hopper, Albert Y. Kim, Chester Ismay (https://moderndive.github.io/moderndive_labs/index.html)ModernDive: Ismay Kim (2021) free Problem Sets authored Jenny Smetzer, William Hopper, Albert Y. Kim, Chester Ismay (https://moderndive.github.io/moderndive_labs/index.html)R Data Science (r4ds): Wickham Grolemund (2021)R Data Science (r4ds): Wickham Grolemund (2021)Data Science Box (https://datasciencebox.org/) free book Diez, √áetinkaya-Rundel, Barr (2019)Data Science Box (https://datasciencebox.org/) free book Diez, √áetinkaya-Rundel, Barr (2019)One thank people enough contribution  community !Credit: https://xkcd.com/2400/","code":""},{"path":"index.html","id":"reproducibility","chapter":"Preface","heading":"Reproducibility","text":"book written RStudio using Bookdown compiled R version 4.1.0 (2021-05-18). need following packages reproduce examples work exercises:complete information last session build book:work licensed Creative Commons Attribution-NonCommercial-ShareAlike 4.0 International License.","code":"## R version 4.1.0 (2021-05-18)\n## Platform: x86_64-pc-linux-gnu (64-bit)\n## Running under: Ubuntu 20.10\n## \n## Matrix products: default\n## BLAS:   /usr/lib/x86_64-linux-gnu/atlas/libblas.so.3.10.3\n## LAPACK: /usr/lib/x86_64-linux-gnu/atlas/liblapack.so.3.10.3\n## \n## locale:\n##  [1] LC_CTYPE=de_DE.UTF-8       LC_NUMERIC=C              \n##  [3] LC_TIME=de_DE.UTF-8        LC_COLLATE=de_DE.UTF-8    \n##  [5] LC_MONETARY=de_DE.UTF-8    LC_MESSAGES=de_DE.UTF-8   \n##  [7] LC_PAPER=de_DE.UTF-8       LC_NAME=C                 \n##  [9] LC_ADDRESS=C               LC_TELEPHONE=C            \n## [11] LC_MEASUREMENT=de_DE.UTF-8 LC_IDENTIFICATION=C       \n## \n## attached base packages:\n## [1] stats     graphics  grDevices utils     datasets  methods   base     \n## \n## other attached packages:\n##  [1] DT_0.18           forcats_0.5.1     stringr_1.4.0     dplyr_1.0.7      \n##  [5] purrr_0.3.4       readr_1.4.0       tidyr_1.1.3       tibble_3.1.2     \n##  [9] ggplot2_3.3.5     tidyverse_1.3.1   kableExtra_1.3.4  fontawesome_0.2.1\n## \n## loaded via a namespace (and not attached):\n##  [1] Rcpp_1.0.6        svglite_2.0.0     lubridate_1.7.10  tufte_0.10       \n##  [5] rprojroot_2.0.2   assertthat_0.2.1  digest_0.6.27     utf8_1.2.1       \n##  [9] R6_2.5.0          cellranger_1.1.0  backports_1.2.1   reprex_2.0.0     \n## [13] evaluate_0.14     highr_0.9         httr_1.4.2        pillar_1.6.1     \n## [17] rlang_0.4.11      readxl_1.3.1      rstudioapi_0.13   jquerylib_0.1.4  \n## [21] rmarkdown_2.9     desc_1.3.0        webshot_0.5.2     htmlwidgets_1.5.3\n## [25] munsell_0.5.0     broom_0.7.6       compiler_4.1.0    modelr_0.1.8     \n## [29] xfun_0.24         pkgconfig_2.0.3   systemfonts_1.0.2 htmltools_0.5.1.1\n## [33] downlit_0.2.1     tidyselect_1.1.1  bookdown_0.22.3   fansi_0.5.0      \n## [37] viridisLite_0.4.0 crayon_1.4.1      dbplyr_2.1.1      withr_2.4.2      \n## [41] grid_4.1.0        jsonlite_1.7.2    gtable_0.3.0      lifecycle_1.0.0  \n## [45] DBI_1.1.1         magrittr_2.0.1    scales_1.1.1      cli_3.0.0        \n## [49] stringi_1.6.2     fs_1.5.0          xml2_1.3.2        bslib_0.2.5.1    \n## [53] ellipsis_0.3.2    generics_0.1.0    vctrs_0.3.8       tools_4.1.0      \n## [57] glue_1.4.2        hms_1.1.0         yaml_2.2.1        colorspace_2.0-2 \n## [61] sessioninfo_1.1.1 rvest_1.0.0       knitr_1.33        haven_2.4.1      \n## [65] sass_0.4.0"},{"path":"introduction-to-r-and-rstudio-server.html","id":"introduction-to-r-and-rstudio-server","chapter":"1 Introduction to R and RStudio Server","heading":"1 Introduction to R and RStudio Server","text":"\nLogin RStudio Server Pro\n\nUpload download files server\n\nUse R calculator\n\nCreate first objects R\n\nfirst plot\nchapter introduces R RStudio ‚Äôll using throughout course learn statistical concepts analyse real data. clarify : R name programming language RStudio convenient development environment make life easier.Today begin fundamental building blocks R RStudio: interface, creating saving files, basic commands.","code":""},{"path":"introduction-to-r-and-rstudio-server.html","id":"opening-rstudio-server-pro","chapter":"1 Introduction to R and RStudio Server","heading":"1.1 Opening RStudio Server Pro","text":"work RStudio Server Pro, online R System. Thus, don‚Äôt need install R RStudio computer (yet). receive login password server. share credentials. case difficulties might need login RStudio Server account. allow , need sign agreement email .can login server, need activate VPN client. familiar VPN client, please visit website.login RStudio Server, click hier. copy address browser: https://cheops-rstudio-edu.rrz.uni-koeln.de:8787/auth-sign-.htm. logging , see home interface (Figure 1.1).\nFigure 1.1: RStudio Server Pro Home\nstart new session, click button New Session next R symbol choose following settings (can rename session wish):\nFigure 1.2: Starting new session\n","code":""},{"path":"introduction-to-r-and-rstudio-server.html","id":"the-rstudio-interface","chapter":"1 Introduction to R and RStudio Server","heading":"1.2 The RStudio interface","text":"RStudio Server see window looks like Figure 1.3.\nFigure 1.3: RStudio interface\npanel left action happens. ‚Äôs called console. Every time launch RStudio, text top console telling version R ‚Äôre running.panel upper right contains workspace. shows variables objects define R session, history commands enter.plots generate show panel lower right corner. also can browse files, access help files, upload download files.","code":""},{"path":"introduction-to-r-and-rstudio-server.html","id":"file-management","chapter":"1 Introduction to R and RStudio Server","heading":"1.3 File management","text":"start making data folder RStudio Server can use store data sets. Click Files tab lower right panel, New Folder tab. Enter folder name data window opens, click OK. now new folder!Next, go course site, download file meteo.csv posted week‚Äôs session. Put location computer remember! highly suggest also make folder course data folder computer store material course.access files stored hard drive computer RStudio Server, need upload computer server. upload data set click RStudio Server data folder , click upload button, like :\nFigure 1.4: Upload files\nwindow opens, browse stored data set computer, click data file, click OK. Open data folder RStudio Server, make sure data . can upload sort file like .anything meteo.csv file, except learning upload .download file first mark (can mark several files) clicking little square left . , click button > Export > Download (Figures 1.5 1.6). Save file(s) computer.\nFigure 1.5: Select files download\n\nFigure 1.6: Save files\n","code":""},{"path":"introduction-to-r-and-rstudio-server.html","id":"practice-on-your-own","chapter":"1 Introduction to R and RStudio Server","heading":"1.4 Practice on your own!","text":"complete problem set next run Exercises, submit R script (.e.¬†.R file) answers Exercises. need type text, don‚Äôt forget use comment sign # typing text R misinterpret text commands.\nRemember save work go along! Click save button upper left hand corner window.\nstart exercises C.1.1 C.1.2 class. Finish exercises produce first plot exercise C.1.3 üòÑ.","code":""},{"path":"introduction-to-r-and-rstudio-server.html","id":"turning-in-your-work","chapter":"1 Introduction to R and RStudio Server","heading":"1.5 Turning in your work","text":"Save R script download .R file computer.Upload .R file ILIAS. find upload option today‚Äôs session.receive solution file deadline.\nsure upload deadline!\n","code":""},{"path":"introduction-to-r-and-rstudio-server.html","id":"logging-out-of-the-server","chapter":"1 Introduction to R and RStudio Server","heading":"1.6 Logging out of the server","text":"classes students using server. keep fast possible, best sign done. follow steps closing R Markdown document :Save work, .e.¬†R document.Click orange button far right corner screen quit R.Choose don‚Äôt save Workspace image.browser refreshes, can click button Sign next login top right.signed !","code":""},{"path":"introduction-to-r-and-rstudio-server.html","id":"reading-assignment","chapter":"1 Introduction to R and RStudio Server","heading":"1.7 Reading assignment","text":"Chapters 1.1. 1.2 Ismay Kim (2021)","code":""},{"path":"using-r-markdown.html","id":"using-r-markdown","chapter":"2 Using R Markdown","heading":"2 Using R Markdown","text":"\nOpening saving R Notebook\n\nBasic layout R Markdown\n","code":""},{"path":"using-r-markdown.html","id":"opening-a-new-r-notebook","chapter":"2 Using R Markdown","heading":"2.1 Opening a new R Notebook","text":"want write paper, open Word document type ideas , save work . R use document type called R Markdown document. R Markdown documents useful running code, annotating code comments. document can saved, can refer back code later, can used create document types (html, word, pdf, slides) presenting results analyses. R Markdown provides way generate clear reproducible statistical analyses.different types R Markdown documents. usually use R Notebook.open new R Notebook, click little green plus upper left hand select R Notebook image . can leave untitled.\nFigure 2.1: create new R Notebook\nopen new R Notebook, example code can get rid . take care next.","code":""},{"path":"using-r-markdown.html","id":"make-changes-to-a-file","chapter":"2 Using R Markdown","heading":"2.2 Make changes to a file","text":"Let‚Äôs make changes R Markdown file just opened. Using image guideFirst, change title top ‚ÄúGetting know R Notebooks.‚Äù sure keep quotation marks.Second, add author line, following example . need quotation marks!Third, delete everything document line 6 downwards.Fourth, add headers text, exactly following example .Finally, insert called ‚Äúcode chunk.‚Äù click insert button near top centre screen, choose R. greyed box shows type code.final result look like :\nFigure 2.2: R Notebook\n","code":""},{"path":"using-r-markdown.html","id":"saving-a-file","chapter":"2 Using R Markdown","heading":"2.3 Saving a file","text":"suggest create new folder Notebooks save R Notebooks.complete lab work R Notebook file like week, important learn save files.Click File > Save ‚Ä¶Browse Notebooks course folder just createdName file: Session2_lastname_firstname (fill firstname lastname)Click saveThis now saved Notebooks folder server.","code":""},{"path":"using-r-markdown.html","id":"preview","chapter":"2 Using R Markdown","heading":"2.4 Preview","text":"Notebooks great advantage offer preview work. Just click Preview button. preview refreshed every time save notebook.","code":""},{"path":"using-r-markdown.html","id":"other-output-options","chapter":"2 Using R Markdown","heading":"2.5 Other output options","text":"can also produce different outputs R Notebook normal R Markdown file supports different output formats. However, produce .html output, Preview button disappear! bring back, need edit header R Notebook file output: html_notebook.\nNote now R Notebook file (.Rmd) html file (nb.html) Notebooks folder.\nInspect preview notebook see typed formatted. lots tricks controlling formatting knitted html file. instance:putting ## space front text makes large header. example, see ## header R Markdown .Rmd file translates resulting .html output.putting ### space front text makes smaller header!","code":""},{"path":"using-r-markdown.html","id":"entering-and-running-commands","chapter":"2 Using R Markdown","heading":"2.6 Entering and running commands","text":"code chunks put R code R Markdown file. far, preview doesn‚Äôt show anything, put content code chunks yet!Using first code chunk, type following command create new variable called x value 6.arrow <- called ASSIGNMENT OPERATOR, tells R save object called x value 6. similar saving value graphing calculator.\nNote whatever want save must always left assignment operator!!\nactually RUN command console, options:click green triangle code chunkhighlight code hit Control-Enter PC Command-Return MacThink ‚Äúrunning‚Äù code console telling R ‚Äú.‚Äù\nNote now new object workspace, called x!\n\nFigure 2.3: Global environment contains variable x now\n","code":"\nx <- 6"},{"path":"using-r-markdown.html","id":"a-brief-recap-of-data-types","chapter":"2 Using R Markdown","heading":"2.7 A brief recap of data types","text":"far made numeric variable x. many types data objects can make R.First, copy, paste run following command new code chunk make character called favorite_movie. Think characters text opposed numerical values. Note told R character putting quotation marks around Star_Wars.Next, copy, paste run following command new code chunk.makes called vector, named v. data object multiple elements type. vector contains three numbers, 2, 4, 6. c() function says r concatenate values 2, 4, 6, single vector. Note Environment pane vector v contains numbers (listed num).can math vector contains numbers! instance, copy, paste run following command new code chunk. tells R multiply element vector v 3.","code":"\nfavorite_movie <- \"Star_Wars\"\nv <- c(2, 4, 6)\nv * 3"},{"path":"using-r-markdown.html","id":"practice-on-your-own-1","chapter":"2 Using R Markdown","heading":"2.8 Practice on your own!","text":"complete problem set next run Exercises, submit R Notebook file answers Exercises. Please make header Exercises. need answer Exercise text, type text header, next line, white part, need answer Exercise code, insert code chunk header, put code greyed box.\nRemember save work go along! Click save button upper left hand corner R Markdown window.\nAnswer following code code chunk (text necessary). Remember code just instructions R. need run code chunk make R execute instructions!\nCreate variable called y value 7\nMultiply x y, store answer variable named z like : z <- x * y\nnow see favorite_movie, x, v, y, z Environment pane\nAnswer following code code chunk (text necessary). Remember code just instructions R. need run code chunk make R execute instructions!Create variable called y value 7Multiply x y, store answer variable named z like : z <- x * yYou now see favorite_movie, x, v, y, z Environment paneRun following mathematical operation code chunk: 6 + 3\nanswer appear? (please answer text)\nRun following mathematical operation code chunk: 6 + 3Where answer appear? (please answer text)Now add code chunk, save results 6 + 3 variable called .\nanswer appear? (please answer text)\nobject show ? (please answer text)\nNext type code chunk re-run code chunk. happens? (please answer text)\nNow add code chunk, save results 6 + 3 variable called .answer appear? (please answer text)object show ? (please answer text)Next type code chunk re-run code chunk. happens? (please answer text)Run following command new code chunk. ^2.\n^ operator ? (please answer text)\nRun following command new code chunk. ^2.^ operator ? (please answer text)Type following command new code chunk. sum(, x, y)\nsum function. Based output, think sum function ? (please answer text)\nType following command new code chunk. sum(, x, y)sum function. Based output, think sum function ? (please answer text)Click little broom icon upper right hand corner Environment pane. Click yes window opens.\nhappened? (please answer text, don‚Äôt freak )\nClick little broom icon upper right hand corner Environment pane. Click yes window opens.happened? (please answer text, don‚Äôt freak )Go Run button top right R Markdown pane, choose Run (last option)\nhappened? (please answer text)\nGo Run button top right R Markdown pane, choose Run (last option)happened? (please answer text)Recall vector v created earlier. Copy, paste run following code chunk. code accomplish?\nv + 2\n\nPlease answer text.Recall vector v created earlier. Copy, paste run following code chunk. code accomplish?\nv + 2\n\nPlease answer text.Copy, paste, run following code make vector called music, contains music genres. Recall vector data object multiple elements type. data type character. Look environment pane. R tell us vector contains characters, numbers?\nmusic <- c(\"bluegrass\", \"funk\", \"folk\")\n\nPlease answer text.Copy, paste, run following code make vector called music, contains music genres. Recall vector data object multiple elements type. data type character. Look environment pane. R tell us vector contains characters, numbers?\nmusic <- c(\"bluegrass\", \"funk\", \"folk\")\n\nPlease answer text.Now let‚Äôs practice basic formatting. Using formatting tips page figure put following lab report. can get typed white section, text goes. Hint: put line! hit hard return line text.\nItalicize like \nBold like \n\nsuperscript: R2Now let‚Äôs practice basic formatting. Using formatting tips page figure put following lab report. can get typed white section, text goes. Hint: put line! hit hard return line text.\nItalicize like \nBold like \n\nsuperscript: R2","code":""},{"path":"using-r-markdown.html","id":"turning-in-your-work-1","chapter":"2 Using R Markdown","heading":"2.9 Turning in your work","text":"Save R Notebook download .Rmd file computer. don‚Äôt need download .nb.html file.Upload R Notebook ILIAS. find upload option today‚Äôs session.receive solution file deadline.\nsure upload deadline!\n","code":""},{"path":"what-is-data.html","id":"what-is-data","chapter":"3 What is data?","heading":"3 What is data?","text":"\nInstall R package\n\nLoad installed data set\n\nExplore data set recognize type variables\nData can anything üòÑ. Usually store data rectangular form, .e.¬†variables columns observations rows. two dedicated object formats store data, namely data.frame() tibble(). similar characteristics, however, tibble considered modern form data frame offers advantages (details later).chapter, look data set called palmerpenguins. provided dedicated package, let‚Äôs install package first.","code":""},{"path":"what-is-data.html","id":"installing-r-packages","chapter":"3 What is data?","heading":"3.1 Installing R packages","text":"Packages available official CRAN (Comprehensive R Archive Network) can installed function install.packages('name_of_the_package'). important provide name package quotes (single double).load package, use function library(name_of_the_package), time without quotes!","code":"\ninstall.packages('palmerpenguins')\nlibrary(palmerpenguins)"},{"path":"what-is-data.html","id":"welcome-the-penguins","chapter":"3 What is data?","heading":"3.2 Welcome the penguins!","text":"\nFigure 3.1: Artwork @allison_horst\npackage dedicated website really worth visiting. package contains two data sets, explore shorter one, called penguins. load data set installed package, use function data(\"name_of_data_set\"). sure put name data set quotes (single double).Let‚Äôs look object penguins.object tibble contains data set 344 rows 8 columns, meaning 8 variables measured 344 animals. first column contains variable species , guessed , shows species animal. variable -called factor (indicated <fct> species). means, contains categorical information certain number (usually small one) distinct values called levels. levels case areThe code uses $ sign access whole column (.e.¬†variable) data set. handy alternative square bracket method. syntax name_of_data_set$name_of_variable.also numerical variables tibble. numerical variable can continuous, e.g.¬†bill_length_mm (indicated <dbl> meaning double), meaning contains decimal numbers discrete, e.g.¬†year (indicated <int> meaning integer), meaning contains integers (whole numbers).summarize data set, can use function summary().","code":"\ndata(\"penguins\")\npenguins## # A tibble: 344 x 8\n##    species island    bill_length_mm bill_depth_mm flipper_length_mm body_mass_g\n##    <fct>   <fct>              <dbl>         <dbl>             <int>       <int>\n##  1 Adelie  Torgersen           39.1          18.7               181        3750\n##  2 Adelie  Torgersen           39.5          17.4               186        3800\n##  3 Adelie  Torgersen           40.3          18                 195        3250\n##  4 Adelie  Torgersen           NA            NA                  NA          NA\n##  5 Adelie  Torgersen           36.7          19.3               193        3450\n##  6 Adelie  Torgersen           39.3          20.6               190        3650\n##  7 Adelie  Torgersen           38.9          17.8               181        3625\n##  8 Adelie  Torgersen           39.2          19.6               195        4675\n##  9 Adelie  Torgersen           34.1          18.1               193        3475\n## 10 Adelie  Torgersen           42            20.2               190        4250\n## # ‚Ä¶ with 334 more rows, and 2 more variables: sex <fct>, year <int>\nlevels(penguins$species)## [1] \"Adelie\"    \"Chinstrap\" \"Gentoo\"\nsummary(penguins)##       species          island    bill_length_mm  bill_depth_mm  \n##  Adelie   :152   Biscoe   :168   Min.   :32.10   Min.   :13.10  \n##  Chinstrap: 68   Dream    :124   1st Qu.:39.23   1st Qu.:15.60  \n##  Gentoo   :124   Torgersen: 52   Median :44.45   Median :17.30  \n##                                  Mean   :43.92   Mean   :17.15  \n##                                  3rd Qu.:48.50   3rd Qu.:18.70  \n##                                  Max.   :59.60   Max.   :21.50  \n##                                  NA's   :2       NA's   :2      \n##  flipper_length_mm  body_mass_g       sex           year     \n##  Min.   :172.0     Min.   :2700   female:165   Min.   :2007  \n##  1st Qu.:190.0     1st Qu.:3550   male  :168   1st Qu.:2007  \n##  Median :197.0     Median :4050   NA's  : 11   Median :2008  \n##  Mean   :200.9     Mean   :4202                Mean   :2008  \n##  3rd Qu.:213.0     3rd Qu.:4750                3rd Qu.:2009  \n##  Max.   :231.0     Max.   :6300                Max.   :2009  \n##  NA's   :2         NA's   :2"},{"path":"what-is-data.html","id":"the-square-braces-revisited","chapter":"3 What is data?","heading":"3.3 The square braces revisited","text":"already know access certain position inside vector. tibble tow-dimensional object, rows columns. access particular measurement, need provide , row column index. following code picks value first row third column:","code":"\npenguins[1, 3]## # A tibble: 1 x 1\n##   bill_length_mm\n##            <dbl>\n## 1           39.1"},{"path":"what-is-data.html","id":"lets-see-them","chapter":"3 What is data?","heading":"3.4 Let‚Äôs see them","text":"talk much data visualisation later. now, just use code visualize relationship flipper length body mass animals.","code":"\nlibrary(ggplot2)\n\nggplot(data = penguins, mapping = aes(x = flipper_length_mm, y = body_mass_g, col = species)) +\n  geom_point() +\n  xlab('Flipper length (mm)') +\n  ylab('Body mass (g)')"},{"path":"what-is-data.html","id":"practice-on-your-own-2","chapter":"3 What is data?","heading":"3.5 Practice on your own!","text":"many categorical many numerical variables ? Consult help.many categorical many numerical variables ? Consult help.many Gentoo penguins present data set?many Gentoo penguins present data set?time span measurements?time span measurements?Find levels variable island.Find levels variable island.challenge ü§ì. Take code produced visualisation flipper length body mass animals. Make educated guess change code produces visualisation bill depth vs.¬†body mass. Can also guess adjust label x axis?challenge ü§ì. Take code produced visualisation flipper length body mass animals. Make educated guess change code produces visualisation bill depth vs.¬†body mass. Can also guess adjust label x axis?","code":""},{"path":"what-is-data.html","id":"reading-assignment-1","chapter":"3 What is data?","heading":"3.6 Reading assignment","text":"Chapter 1.3 Ismay Kim (2021).","code":""},{"path":"what-is-data.html","id":"turning-in-your-work-2","chapter":"3 What is data?","heading":"3.7 Turning in your work","text":"Save R Notebook download .Rmd file computer. don‚Äôt need download .nb.html file.Upload R Notebook ILIAS. find upload option today‚Äôs session.receive solution file deadline.\nsure upload deadline!\n","code":""},{"path":"what-is-data.html","id":"additional-reading","chapter":"3 What is data?","heading":"3.8 Additional reading","text":"case prefer flights penguins, can look data exploration Chapter 1.4 Ismay Kim (2021)","code":""},{"path":"import-visualize-and-explore-data.html","id":"import-visualize-and-explore-data","chapter":"4 Import, visualize and explore data","heading":"4 Import, visualize and explore data","text":"\nImport data R\n\nExplain general call function ggplot()\n\nPlot 5 frequently used types graphics\n","code":""},{"path":"import-visualize-and-explore-data.html","id":"data-import-from-text-files","chapter":"4 Import, visualize and explore data","heading":"4.1 Data import from text files","text":"import data set text file (e.g.¬†.csv, .txt, .dat) R, use library readr part tydiverse. first load library.Let‚Äôs assume data stored folder data. case, change path accordingly. load data, can chose among several different functions start read_. generic one read_delim() can specify columns separated (delimited) data file.Let‚Äôs look data. data set greenhouse gas emissions source sector EU downloaded eurostat 2021-04-30. contains greenhouse gas emissions CO2 equivalent, Mio tonnes, per vehicle type. data base great source data reports üòÑ.result reading data function library readr always tibble. can see none variables factor. default behaviour readr. want variable coded factor transform hand, preferably functions package forcats.Let‚Äôs quick look data set.character variables, summary() count frequency different values. However, can get information function unique().data set contains measurements 33 EU countries. can also ask different types vehicle recorded.","code":"\nlibrary(tidyverse)\nemissions <- read_delim(file = 'data/emissions.csv', delim = ';')## \n## ‚îÄ‚îÄ Column specification ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\n## cols(\n##   unit = col_character(),\n##   airpol = col_character(),\n##   vehicle = col_character(),\n##   geo = col_character(),\n##   time = col_date(format = \"\"),\n##   values = col_double()\n## )\nemissions## # A tibble: 2,871 x 6\n##    unit     airpol                  vehicle    geo             time       values\n##    <chr>    <chr>                   <chr>      <chr>           <date>      <dbl>\n##  1 Million‚Ä¶ Greenhouse gases (CO2,‚Ä¶ Fuel comb‚Ä¶ Austria         2018-01-01  14.4 \n##  2 Million‚Ä¶ Greenhouse gases (CO2,‚Ä¶ Fuel comb‚Ä¶ Belgium         2018-01-01  14.4 \n##  3 Million‚Ä¶ Greenhouse gases (CO2,‚Ä¶ Fuel comb‚Ä¶ Bulgaria        2018-01-01   5.78\n##  4 Million‚Ä¶ Greenhouse gases (CO2,‚Ä¶ Fuel comb‚Ä¶ Switzerland     2018-01-01  11.0 \n##  5 Million‚Ä¶ Greenhouse gases (CO2,‚Ä¶ Fuel comb‚Ä¶ Cyprus          2018-01-01   1.38\n##  6 Million‚Ä¶ Greenhouse gases (CO2,‚Ä¶ Fuel comb‚Ä¶ Czechia         2018-01-01  11.9 \n##  7 Million‚Ä¶ Greenhouse gases (CO2,‚Ä¶ Fuel comb‚Ä¶ Germany (until‚Ä¶ 2018-01-01  97.8 \n##  8 Million‚Ä¶ Greenhouse gases (CO2,‚Ä¶ Fuel comb‚Ä¶ Denmark         2018-01-01   6.85\n##  9 Million‚Ä¶ Greenhouse gases (CO2,‚Ä¶ Fuel comb‚Ä¶ Estonia         2018-01-01   1.52\n## 10 Million‚Ä¶ Greenhouse gases (CO2,‚Ä¶ Fuel comb‚Ä¶ Greece          2018-01-01   7.61\n## # ‚Ä¶ with 2,861 more rows\nsummary(emissions)##      unit              airpol            vehicle              geo           \n##  Length:2871        Length:2871        Length:2871        Length:2871       \n##  Class :character   Class :character   Class :character   Class :character  \n##  Mode  :character   Mode  :character   Mode  :character   Mode  :character  \n##                                                                             \n##                                                                             \n##                                                                             \n##                                                                             \n##       time                values         \n##  Min.   :1990-01-01   Min.   :  0.00609  \n##  1st Qu.:1997-01-01   1st Qu.:  0.25564  \n##  Median :2004-01-01   Median :  1.92403  \n##  Mean   :2004-01-01   Mean   :  8.52836  \n##  3rd Qu.:2011-01-01   3rd Qu.:  6.93899  \n##  Max.   :2018-01-01   Max.   :119.77824  \n##                       NA's   :232\nlength(unique(emissions$geo))## [1] 33\nunique(emissions$vehicle)## [1] \"Fuel combustion in cars\"                       \n## [2] \"Fuel combustion in heavy duty trucks and buses\"\n## [3] \"Fuel combustion in railways\""},{"path":"import-visualize-and-explore-data.html","id":"visualization-with-the-library-ggplot2","chapter":"4 Import, visualize and explore data","heading":"4.2 Visualization with the library ggplot2","text":"library ggplot2 powerful package data visualisation. name comes grammar graphics hints systematic approach visualisation. nutshell, ggplot2 defines statistical graphic follows:statistical graphic mapping variables data set aesthetic attributes geometric objects.ggplot2, graphic build step step, starting call core function ggplot(). specify following elements:data: data set containing variables visualised.data: data set containing variables visualised.aes: (aesthetic) attributes geometric object visualised. can x y variables, colour, shape, grouping variable etc.aes: (aesthetic) attributes geometric object visualised. can x y variables, colour, shape, grouping variable etc.geom: geometric object want plot, .e.¬†lines, points, bars, boxes etc.geom: geometric object want plot, .e.¬†lines, points, bars, boxes etc.","code":""},{"path":"import-visualize-and-explore-data.html","id":"line-plot","chapter":"4 Import, visualize and explore data","heading":"4.2.1 Line plot","text":"start line plot particularly suited time series. plotting 33 countries one graph much, first filter France emissions cars.call ggplot() prepares plotting area requested, show anything specify geometric object. geometric objects begin geom_. Every step building plot appended core call +.call can verbalised like following:Take data set emissions map following attributes:\nx-axsis variable time\ny-axsis variable values\nTake data set emissions map following attributes:x-axsis variable timeon y-axsis variable valuesPlot data line (geom_line())Plot data line (geom_line())order plot useful, label axes correctly (give title, figure caption shown). done adding function labs().","code":"\nemissions_france <- emissions %>% \n  filter(geo == 'France' & vehicle == 'Fuel combustion in cars')\nggplot(data = emissions_france, mapping = aes(x = time, y = values))\nggplot(data = emissions_france, mapping = aes(x = time, y = values)) +\n  geom_line()\nggplot(data = emissions_france, mapping = aes(x = time, y = values)) + \n  geom_line() +\n  labs(x = 'Time', y = 'Emissions (Mio tons)', title = 'Emissions in France')"},{"path":"import-visualize-and-explore-data.html","id":"point-plot","chapter":"4 Import, visualize and explore data","heading":"4.2.2 Point plot","text":"can add points plot geom_point(). principle, wouldn‚Äôt time series, wan‚Äôt show geom üòÑ.select two countries, aesthetic required distinguish time series. Let‚Äôs select France Italy.plot countries using different colours. Note (yet) select colours hand, specify variable used distinguish time series. colours chosen one country automatically.legend comes free! can change title legend setting colour = 'Country' call labs().","code":"\nggplot(data = emissions_france, mapping = aes(x = time, y = values)) + \n  geom_line() +\n  geom_point() +\n  labs(x = 'Time', y = 'Emissions (Mio tons)', title = 'Emissions in France')\nemissions_france_italy <- emissions %>% \n  filter(geo %in% c('France', 'Italy') & vehicle == 'Fuel combustion in cars')\nggplot(data = emissions_france_italy, mapping = aes(x = time, y = values, colour = geo)) + \n  geom_line() +\n  geom_point() +\n  labs(x = 'Time', y = 'Emissions (Mio tons)', title = 'Emissions in France and Italy', colour = 'Country')"},{"path":"import-visualize-and-explore-data.html","id":"histogram","chapter":"4 Import, visualize and explore data","heading":"4.3 Histogram","text":"Let‚Äôs look distribution emissions year 2018. filter data first.plot data histogram shows absolute frequencies data (.e.¬†many data points fall particular interval emissions). shows distribution continuous variable. histogram, specify x variable, frequencies calculated geom_histogram() directly. specify 25 bins (intervals). familiar kind statistical summaries, please look Appendix Ismay Kim (2021) read part .1.5 Distribution.","code":"\nemissions_2018 <- emissions %>% \n  filter(time == '2018-01-01')\nggplot(data = emissions_2018, mapping = aes(x = values)) +\n  geom_histogram(bins = 25)## Warning: Removed 8 rows containing non-finite values (stat_bin)."},{"path":"import-visualize-and-explore-data.html","id":"boxplot","chapter":"4 Import, visualize and explore data","heading":"4.4 Boxplot","text":"boxplot calculates prominent statistics data set plots form box ‚Äòwhiskers‚Äô (thus also called box--whiskers plot). Basically, calculating summary() (five-numbers: min, max, 25%, 50% 75% quantiles), figure. familiar kind statistical summaries, please look Appendix Ismay Kim (2021) read part .1.4 Five-number summary.Lets look kind summary plot. emissions distributed year? convert time factor variable order display data correctly (try happens don‚Äôt convert ).Hmmm, labels x axis really ugly. Let‚Äôs tune little bit (tuning later sessions).","code":"\nggplot(data = emissions, mapping = aes(x = factor(time), y = values)) +\n  geom_boxplot()## Warning: Removed 232 rows containing non-finite values (stat_boxplot).\nggplot(data = emissions, mapping = aes(x = factor(time), y = values)) +\n  geom_boxplot() +\n  theme(axis.text.x = element_text(angle = 90))## Warning: Removed 232 rows containing non-finite values (stat_boxplot)."},{"path":"import-visualize-and-explore-data.html","id":"barplot","chapter":"4 Import, visualize and explore data","heading":"4.4.1 Barplot","text":"last geom want see geom_bar(). want know many data entries emissions contain per vehicle.Admittedly, boring plot üòÑ, number entries identical.","code":"\nggplot(data = emissions, mapping = aes(x = vehicle)) +\n  geom_bar()"},{"path":"import-visualize-and-explore-data.html","id":"practice-on-your-own-3","chapter":"4 Import, visualize and explore data","heading":"4.5 Practice on your own!","text":"histogram, boxplot barplot plotted labelled correctly. Correct axis labels find good titles graphs.histogram, boxplot barplot plotted labelled correctly. Correct axis labels find good titles graphs.Plot time series GDP data set gapminder France Germany. Filter data like :\nfrance_germany <- gapminder %>% filter(country %% c('France', 'Germany'))Plot time series GDP data set gapminder France Germany. Filter data like :\nfrance_germany <- gapminder %>% filter(country %% c('France', 'Germany'))Plot life expectancy vs.¬†GDP 2007, use data set gapminder. Pick code filtering data task ref. Use aesthetics colour size. educated guess change title legends (google üòÑ).Plot life expectancy vs.¬†GDP 2007, use data set gapminder. Pick code filtering data task ref. Use aesthetics colour size. educated guess change title legends (google üòÑ).GDP distributed Africa Europe 2007? Use data set gapminder. Filter data like :\nafrica_europe <- gapminder2007 %>% filter(continent %% c('Africa', 'Europe')).\n\nPlot data histogram use aesthetic fill instead colour distinguish continents.GDP distributed Africa Europe 2007? Use data set gapminder. Filter data like :\nafrica_europe <- gapminder2007 %>% filter(continent %% c('Africa', 'Europe')).\n\nPlot data histogram use aesthetic fill instead colour distinguish continents.GDP distributed different continents 2007? Use data set gapminder. Plot data boxplot.GDP distributed different continents 2007? Use data set gapminder. Plot data boxplot.many data points gapminder contain per continent? Visualize barplot.many data points gapminder contain per continent? Visualize barplot.","code":""},{"path":"import-visualize-and-explore-data.html","id":"reading-assignment-2","chapter":"4 Import, visualize and explore data","heading":"4.6 Reading assignment","text":"Chapter 2.1 Ismay Kim (2021)","code":""},{"path":"import-visualize-and-explore-data.html","id":"turning-in-your-work-3","chapter":"4 Import, visualize and explore data","heading":"4.7 Turning in your work","text":"Save R Notebook download .Rmd file computer. don‚Äôt need download .nb.html file.Upload R Notebook ILIAS. find upload option today‚Äôs session.receive solution file submission.\nsure upload deadline!\n","code":""},{"path":"import-visualize-and-explore-data.html","id":"additional-reading-1","chapter":"4 Import, visualize and explore data","heading":"4.8 Additional reading","text":"Chapters 2.2 2.9 Ismay Kim (2021)","code":""},{"path":"tidyverse.html","id":"tidyverse","chapter":"5 Explorative workflow with tidyverse","heading":"5 Explorative workflow with tidyverse","text":"\nName core packages tidyverse\n\nApply simple explorative workflow (read, summarize, plot) tidyverse\n\nUse functions dplyr data wrangling\ntidyverse collection R packages data analysis (https://www.tidyverse.org/). shares common philosophy data structure grammar data manipulation visualisation. Although might sound like something alien, tidyverse regular part R functions can mixed base R functions.best introduction tidyverse r4ds: ‚ÄúR Data Science‚Äù (Wickham Grolemund 2021). can read free (https://r4ds..co.nz/).","code":""},{"path":"tidyverse.html","id":"core-packages","chapter":"5 Explorative workflow with tidyverse","heading":"5.1 Core packages","text":"tidyverse comprises 8 core packages installed call install.packages('tidyverse'):Every packages Cheat Sheet, overview functions. get package‚Äôs cheat sheet click name (https://www.tidyverse.org/packages/), scroll section Cheatsheet.Besides core packages, tidyverse also installes long list supplementary packages can find : https://www.tidyverse.org/packages/","code":""},{"path":"tidyverse.html","id":"exploratory-data-analysis","chapter":"5 Explorative workflow with tidyverse","heading":"5.2 Exploratory data analysis","text":"Exploratory data analysis important first step data analysis. using advanced statistical method, exploratory analysis must . comprises roughly following steps:import inspect dataclean (tidy) data necessarysummarize create new variables necessaryplot many different plots possible get good overview patterns data distribution","code":""},{"path":"tidyverse.html","id":"read-data-revisited","chapter":"5 Explorative workflow with tidyverse","heading":"5.2.1 Read data, revisited","text":"load library tidyverse first.Last time used function read_delim() import data R. function general whole family functions, starting read_*: read_csv(), read_csv2() etc. parameters need verify respective help pages want use .exploratory data analysis use data German Meteo Service (Deutscher Wetterdienst) downloaded 2020-05-24 (https://www.dwd.de/DE/leistungen/klimadatendeutschland/klimadatendeutschland.html). data set contains hourly measurements relative air humidity (%) air temperature (¬∞C) three meteo stations, namely Hof, Frankfurt K√∂ln-Bonn. data named meteo.csv.read_delim() reports reading data variables recognizes. good hint spot possible problems. numerical variables read <dbl>? characters recognized <char> etc. code , parameter trim_ws = T removes leading zeroes.Let‚Äôs showr glimps data.data set contains following variables:read_* always returns tibble.","code":"\nlibrary(tidyverse)\ntemp_humid <- read_delim('data/meteo.csv', delim = ';',    trim_ws = T)## \n## ‚îÄ‚îÄ Column specification ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\n## cols(\n##   STATIONS_ID = col_double(),\n##   MESS_DATUM = col_double(),\n##   QN_9 = col_double(),\n##   TT_TU = col_double(),\n##   RF_TU = col_double(),\n##   eor = col_character()\n## )\ntemp_humid## # A tibble: 39,600 x 6\n##    STATIONS_ID MESS_DATUM  QN_9 TT_TU RF_TU eor  \n##          <dbl>      <dbl> <dbl> <dbl> <dbl> <chr>\n##  1        2261 2018111900     3  -2.8    99 eor  \n##  2        2261 2018111901     3  -2.5   100 eor  \n##  3        2261 2018111902     3  -2.3   100 eor  \n##  4        2261 2018111903     3  -2     100 eor  \n##  5        2261 2018111904     3  -1.9    99 eor  \n##  6        2261 2018111905     3  -2.1    99 eor  \n##  7        2261 2018111906     3  -1.8    99 eor  \n##  8        2261 2018111907     3  -1.5    99 eor  \n##  9        2261 2018111908     3  -1.1    99 eor  \n## 10        2261 2018111909     3  -0.6    97 eor  \n## # ‚Ä¶ with 39,590 more rows\nclass(temp_humid)## [1] \"spec_tbl_df\" \"tbl_df\"      \"tbl\"         \"data.frame\""},{"path":"tidyverse.html","id":"date-and-time-made-easy","chapter":"5 Explorative workflow with tidyverse","heading":"5.2.2 Date and time made easy","text":"useful package handle date time called lubridate. part core packages tidyverse installed long list additional packages. use convert variable MESS_DATUM real date-time variable.function ymd_h() converts character vectors date-time objects provided format year, month, day, hour. function different formats; consult help.conversion, variables recognised <dttm> date-time.","code":"\nlibrary(lubridate)\n\ntemp_humid$MESS_DATUM <- ymd_h(temp_humid$MESS_DATUM)\n\ntemp_humid## # A tibble: 39,600 x 6\n##    STATIONS_ID MESS_DATUM           QN_9 TT_TU RF_TU eor  \n##          <dbl> <dttm>              <dbl> <dbl> <dbl> <chr>\n##  1        2261 2018-11-19 00:00:00     3  -2.8    99 eor  \n##  2        2261 2018-11-19 01:00:00     3  -2.5   100 eor  \n##  3        2261 2018-11-19 02:00:00     3  -2.3   100 eor  \n##  4        2261 2018-11-19 03:00:00     3  -2     100 eor  \n##  5        2261 2018-11-19 04:00:00     3  -1.9    99 eor  \n##  6        2261 2018-11-19 05:00:00     3  -2.1    99 eor  \n##  7        2261 2018-11-19 06:00:00     3  -1.8    99 eor  \n##  8        2261 2018-11-19 07:00:00     3  -1.5    99 eor  \n##  9        2261 2018-11-19 08:00:00     3  -1.1    99 eor  \n## 10        2261 2018-11-19 09:00:00     3  -0.6    97 eor  \n## # ‚Ä¶ with 39,590 more rows"},{"path":"tidyverse.html","id":"summarize","chapter":"5 Explorative workflow with tidyverse","heading":"5.2.3 Summarize","text":"three meteo station following IDs:want know many measurements per station data set contains.operator %>% called pipe pronounced . code temp_humid %>% group_by(STATIONS_ID) %>% count() can read : take object temp_humid, group STATIONS_ID count measurments group. pipe operator comes package magrittr (https://magrittr.tidyverse.org/). core operator tidyverse makes code readable easier follow humans. Perhaps beginning, soon ü§ì.","code":"\nstation_ids <-  c('2261' = 'Hof', '1420' = 'Frankfurt', '2667' = 'Koeln')\ntemp_humid %>% \n  group_by(STATIONS_ID) %>% \n  count()## # A tibble: 3 x 2\n## # Groups:   STATIONS_ID [3]\n##   STATIONS_ID     n\n##         <dbl> <int>\n## 1        1420 13200\n## 2        2261 13200\n## 3        2667 13200"},{"path":"tidyverse.html","id":"the-grammar-of-data-manipulation-dplyr","chapter":"5 Explorative workflow with tidyverse","heading":"5.2.4 The grammar of data manipulation ‚Äì dplyr","text":"function count() part library dplyr, collection functions named verbs. Thus, easy imagine function üòÑ). 5 core functions :want know many measurements recorded particular meteo station, first filter ID:function filter() accepts logical tests. every row STATION_ID, == checks whether entry equals 2667. == logical operator means left side equals right sight. case, == returns TRUE otherwise returns FALSE. filter() selects rows TRUE returned. useful logical operators :logical boolean operators handeled tutorials (see ) help pages filter().can combine several test operator |, example. , want filter rows containing either ID 2667 ID 2261:can achieved excluding third station:alternative, can use operator %% checks whether row contains one entries vector.","code":"\ntemp_humid %>% \n  filter(STATIONS_ID == '2667') %>%\n  count()## # A tibble: 1 x 1\n##       n\n##   <int>\n## 1 13200\ntemp_humid %>% \n  filter(STATIONS_ID == '2667' | STATIONS_ID == '2261') %>%\n  group_by(STATIONS_ID) %>% \n  count()## # A tibble: 2 x 2\n## # Groups:   STATIONS_ID [2]\n##   STATIONS_ID     n\n##         <dbl> <int>\n## 1        2261 13200\n## 2        2667 13200\ntemp_humid %>% \n  filter(STATIONS_ID != '1420') %>%\n  group_by(STATIONS_ID) %>% \n  count()## # A tibble: 2 x 2\n## # Groups:   STATIONS_ID [2]\n##   STATIONS_ID     n\n##         <dbl> <int>\n## 1        2261 13200\n## 2        2667 13200\ntemp_humid %>% \n  filter(STATIONS_ID %in% c('2667', '2261')) %>%\n  group_by(STATIONS_ID) %>% \n  count()## # A tibble: 2 x 2\n## # Groups:   STATIONS_ID [2]\n##   STATIONS_ID     n\n##         <dbl> <int>\n## 1        2261 13200\n## 2        2667 13200"},{"path":"tidyverse.html","id":"visualise","chapter":"5 Explorative workflow with tidyverse","heading":"5.2.5 Visualise","text":"plot time series use trick split along three different plots function facet_wrap(). needs variable separate data plots chose STATIONS_ID. splitting variable must preceeded ~.","code":"\nggplot(data = temp_humid, aes(x = MESS_DATUM, y = TT_TU)) + \n  geom_line() +\n  facet_wrap(~STATIONS_ID, nrow = 3) +\n  labs(x = 'Time', y = 'Temperature (¬∞C)')"},{"path":"tidyverse.html","id":"new-variables-with-mutate","chapter":"5 Explorative workflow with tidyverse","heading":"5.2.6 New variables with mutate()","text":"want calculate monthly means standard deviations air temperature humidity. First, need generate temporal information, namely year month used group temperature values calculate mean() sd(). can achieved functions year()month() library lubridate. function mutate() can create new variables data object.next step, create new data set calculate means standard deviations. order get station, year month, group data accordingly. group several variables, just enumerate comma (quotation c() necessary).new object monthly_means grouped tibble, indicated grouped_df output str() shows structure object.calculations better done ungrouped data. Therefore, remove grouping. change data .plot monthly data, need proper monthly date object. attribute monthly means first respective month. , lubridate helps task. function parse_dat_time() genral function taking character string returning date-time object. need ‚Äúglue‚Äù variables year month together paste0() (yes, zero, O!) form string specify orders = 'ym', .e.¬†year month. Finally, relocate() new variable year_month variable year convenience (, created last varialbe data set).Now, can plot mean air temperature.can also visualise standard deviations.use semi-transparent band show variability (standard deviation).One last detail. titles top facets show station IDs. employee German Meteo Service, probably know hart. better use city names. vector station_ids called named vector right structure change titles facets: assignes every id city name, .e.¬†2261 = ‚ÄòHof.‚Äôuse station_ids change titles:","code":"\ntemp_humid <- temp_humid %>% \n  mutate(year = year(MESS_DATUM),\n         month = month(MESS_DATUM))\n\ntemp_humid## # A tibble: 39,600 x 8\n##    STATIONS_ID MESS_DATUM           QN_9 TT_TU RF_TU eor    year month\n##          <dbl> <dttm>              <dbl> <dbl> <dbl> <chr> <dbl> <dbl>\n##  1        2261 2018-11-19 00:00:00     3  -2.8    99 eor    2018    11\n##  2        2261 2018-11-19 01:00:00     3  -2.5   100 eor    2018    11\n##  3        2261 2018-11-19 02:00:00     3  -2.3   100 eor    2018    11\n##  4        2261 2018-11-19 03:00:00     3  -2     100 eor    2018    11\n##  5        2261 2018-11-19 04:00:00     3  -1.9    99 eor    2018    11\n##  6        2261 2018-11-19 05:00:00     3  -2.1    99 eor    2018    11\n##  7        2261 2018-11-19 06:00:00     3  -1.8    99 eor    2018    11\n##  8        2261 2018-11-19 07:00:00     3  -1.5    99 eor    2018    11\n##  9        2261 2018-11-19 08:00:00     3  -1.1    99 eor    2018    11\n## 10        2261 2018-11-19 09:00:00     3  -0.6    97 eor    2018    11\n## # ‚Ä¶ with 39,590 more rows\nmonthly_means <- temp_humid %>%\n  group_by(STATIONS_ID, year, month) %>% \n  summarize(mean_T = mean(TT_TU), mean_RH = mean(RF_TU),\n            sd_T = sd(TT_TU), sd_RH = sd(RF_TU))## `summarise()` has grouped output by 'STATIONS_ID', 'year'. You can override using the `.groups` argument.\nmonthly_means## # A tibble: 57 x 7\n## # Groups:   STATIONS_ID, year [9]\n##    STATIONS_ID  year month mean_T mean_RH  sd_T sd_RH\n##          <dbl> <dbl> <dbl>  <dbl>   <dbl> <dbl> <dbl>\n##  1        1420  2018    11   4.00    79.7  1.82  9.96\n##  2        1420  2018    12   4.73    83.7  4.20 11.7 \n##  3        1420  2019     1   2.12    79.3  3.76 10.0 \n##  4        1420  2019     2   4.48    74.1  4.69 17.7 \n##  5        1420  2019     3   8.28    68.5  4.08 16.1 \n##  6        1420  2019     4  11.7     61.0  5.52 21.8 \n##  7        1420  2019     5  12.7     67.5  4.64 20.1 \n##  8        1420  2019     6  21.4     60.6  6.05 21.2 \n##  9        1420  2019     7  21.6     55.6  5.90 21.8 \n## 10        1420  2019     8  20.7     65.6  4.94 20.8 \n## # ‚Ä¶ with 47 more rows\nstr(monthly_means)## grouped_df [57 √ó 7] (S3: grouped_df/tbl_df/tbl/data.frame)\n##  $ STATIONS_ID: num [1:57] 1420 1420 1420 1420 1420 1420 1420 1420 1420 1420 ...\n##  $ year       : num [1:57] 2018 2018 2019 2019 2019 ...\n##  $ month      : num [1:57] 11 12 1 2 3 4 5 6 7 8 ...\n##  $ mean_T     : num [1:57] 4 4.73 2.12 4.48 8.28 ...\n##  $ mean_RH    : num [1:57] 79.7 83.7 79.3 74.1 68.5 ...\n##  $ sd_T       : num [1:57] 1.82 4.2 3.76 4.69 4.08 ...\n##  $ sd_RH      : num [1:57] 9.96 11.68 10.04 17.73 16.1 ...\n##  - attr(*, \"groups\")= tibble [9 √ó 3] (S3: tbl_df/tbl/data.frame)\n##   ..$ STATIONS_ID: num [1:9] 1420 1420 1420 2261 2261 ...\n##   ..$ year       : num [1:9] 2018 2019 2020 2018 2019 ...\n##   ..$ .rows      : list<int> [1:9] \n##   .. ..$ : int [1:2] 1 2\n##   .. ..$ : int [1:12] 3 4 5 6 7 8 9 10 11 12 ...\n##   .. ..$ : int [1:5] 15 16 17 18 19\n##   .. ..$ : int [1:2] 20 21\n##   .. ..$ : int [1:12] 22 23 24 25 26 27 28 29 30 31 ...\n##   .. ..$ : int [1:5] 34 35 36 37 38\n##   .. ..$ : int [1:2] 39 40\n##   .. ..$ : int [1:12] 41 42 43 44 45 46 47 48 49 50 ...\n##   .. ..$ : int [1:5] 53 54 55 56 57\n##   .. ..@ ptype: int(0) \n##   ..- attr(*, \".drop\")= logi TRUE\nmonthly_means <- ungroup(monthly_means)\nmonthly_means <- monthly_means %>%\n  mutate(year_month = parse_date_time(paste0(year, month), orders = 'ym', tz = 'CET')) %>% \n  relocate(year_month, .before = year)\n\nmonthly_means## # A tibble: 57 x 8\n##    STATIONS_ID year_month           year month mean_T mean_RH  sd_T sd_RH\n##          <dbl> <dttm>              <dbl> <dbl>  <dbl>   <dbl> <dbl> <dbl>\n##  1        1420 2018-11-01 00:00:00  2018    11   4.00    79.7  1.82  9.96\n##  2        1420 2018-12-01 00:00:00  2018    12   4.73    83.7  4.20 11.7 \n##  3        1420 2019-01-01 00:00:00  2019     1   2.12    79.3  3.76 10.0 \n##  4        1420 2019-02-01 00:00:00  2019     2   4.48    74.1  4.69 17.7 \n##  5        1420 2019-03-01 00:00:00  2019     3   8.28    68.5  4.08 16.1 \n##  6        1420 2019-04-01 00:00:00  2019     4  11.7     61.0  5.52 21.8 \n##  7        1420 2019-05-01 00:00:00  2019     5  12.7     67.5  4.64 20.1 \n##  8        1420 2019-06-01 00:00:00  2019     6  21.4     60.6  6.05 21.2 \n##  9        1420 2019-07-01 00:00:00  2019     7  21.6     55.6  5.90 21.8 \n## 10        1420 2019-08-01 00:00:00  2019     8  20.7     65.6  4.94 20.8 \n## # ‚Ä¶ with 47 more rows\nggplot(data = monthly_means, aes(x = year_month, y = mean_T, col = factor(STATIONS_ID))) + \n  geom_line() + \n  labs(x = 'Time', y = 'Temperature (¬∞C)', color = 'Meteo station')\nggplot(monthly_means, aes(x = year_month, y = mean_T, ymin = mean_T - sd_T, ymax = mean_T + sd_T)) +\n  geom_errorbar() +\n  geom_point() +\n  facet_wrap(~STATIONS_ID, nrow = 3) + \n  labs(x = 'Time', y = 'Temperature (¬∞C)')\nggplot(monthly_means, aes(x = year_month, y = mean_T, ymin = mean_T - sd_T, ymax = mean_T + sd_T)) +\n  geom_ribbon(alpha = 0.5) +\n  geom_line() +\n  facet_wrap(~STATIONS_ID, nrow = 3) + \n  labs(x = 'Time', y = 'Temperature (¬∞C)')\nstation_ids##        2261        1420        2667 \n##       \"Hof\" \"Frankfurt\"     \"Koeln\"\nggplot(monthly_means, aes(x = year_month, y = mean_T, ymin = mean_T - sd_T, ymax = mean_T + sd_T)) +\n  geom_ribbon(alpha = 0.5) +\n  geom_line() +\n  facet_wrap(~STATIONS_ID, nrow = 3, labeller = labeller(STATIONS_ID = station_ids)) + \n  labs(x = 'Time', y = 'Temperature (¬∞C)')"},{"path":"tidyverse.html","id":"practice-on-your-own-4","chapter":"5 Explorative workflow with tidyverse","heading":"5.3 Practice on your own!","text":"Plot means standard deviations air humidity instead air temperature.Plot means standard deviations air humidity instead air temperature.tutorials ‚ÄúWork data‚Äù Primers collection RStudio Cloud. can access tutorials : https://rstudio.cloud/learn/primers/2Do tutorials ‚ÄúWork data‚Äù Primers collection RStudio Cloud. can access tutorials : https://rstudio.cloud/learn/primers/2Do tutorials ‚ÄúVisualize Data‚Äù Primers collection RStudio Cloud. can access tutorials :https://rstudio.cloud/learn/primers/3Do tutorials ‚ÄúVisualize Data‚Äù Primers collection RStudio Cloud. can access tutorials :https://rstudio.cloud/learn/primers/3","code":""},{"path":"tidyverse.html","id":"reading-assignment-3","chapter":"5 Explorative workflow with tidyverse","heading":"5.4 Reading assignment","text":"Read chapter 3 (3.5) Ismay Kim (2021)","code":""},{"path":"tidyverse.html","id":"additional-reading-and-videos","chapter":"5 Explorative workflow with tidyverse","heading":"5.5 Additional reading and videos","text":"information statistical graphical summaries geoms: R4DS Wickham Grolemund (2021): Chapter 5 ‚ÄúData transformation‚Äùinformation statistical graphical summaries geoms: R4DS Wickham Grolemund (2021): Chapter 5 ‚ÄúData transformation‚Äùlive exploratory data analysis main author tidyverse, Hadley Wickham. Really informative, Dr.¬†Wickham types fast üòÑ.live exploratory data analysis main author tidyverse, Hadley Wickham. Really informative, Dr.¬†Wickham types fast üòÑ.","code":""},{"path":"sampling.html","id":"sampling","chapter":"6 Sampling and variability","heading":"6 Sampling and variability","text":"\nConduct random sampling using computer\n\nExplain variability random sampling\n\nCalculate sampling distributions\n\nCalculate standard error\nchapter start journey statistical inference. Statistical inference simply inference wants go beyond analysis single data sets. wants know whether patterns observed single data set can generalized larger context. Often, context called population. generalization techniques nothing else estimation population parameters. example, want know mean income large group people, can either ask every person (time money ) ask cleverly chosen group , sample, try estimate mean income, mean income whole group.Another setting, want use inference, experiments, e.g.¬†lab. Imagine want study influence increased temperature growth plant species. design experiment plants species grown ambient temperature (control group) increased temperature (treatment group). measure growth want know whether difference observed due chance whether real difference, effect treatment. real difference, large precisely can estimate effect. questions can answered using inference.inference based data science computer. Nowadays, computational power usually longer problem cool statistical inference can done based computer simulations called resampling techniques.chapter learn use computer experiment draw samples simulated data set. see every random sample different. experience elucidate concept randomness chance variability.","code":""},{"path":"sampling.html","id":"random-sampling-of-data","chapter":"6 Sampling and variability","heading":"6.1 Random sampling of data","text":"use following libraries. library infer dedicated package tidy inference.simulate data set, population, invent getsmarter university 12000 students. code draws random numbers simulates following variables:student_id: 1 12000gender: male femaletravel_time: time students travel university minutesresidence: type place residents, either town = urban countryside = ruraltransport: students travel/come universitytime_lib: time students spend university library minutesWe organise variables tibble call getsmarter_pop.draw random numbers using R, every time rerun code, new numbers generated. reproducible population, use function set.seed(). accepts parameter integer. integer use really matter long use every time rerun code. setting seed, set random number generate R certain reproducible state. numbers still random, reproducible üòÑ.conduct survey among students getsmarter record values variables listed . select students randomly. Therefore, data set generate survey random sample. simulate survey, use function rep_sample_n(). samples repeatedly n data points (students case) given data set (population getsmarter_pop).sample randomly (use random number generator R ), need set seed reproducibility. simulate survey 50 students define survey size survey_size <- 50. survey done , parameter reps = 1, students can interviewed , parameter replace = FALSE, function rep_sample_n().function rep_sample_n returns grouped tibble. variable replicate contained number 1 rep = 1. indicator variable replication.many students survey live town many countryside?Instead actual numbers, want express residence proportions.42% survey students live countryside 58% town.proportions obtain repeated survey? Let‚Äôs repeat survey 33 times observe variability residence. unrealistic scenario real life, however, computer experiment problem. set reps = 33.Now survey_reps shows 33 replicates variable replicate ranges 1 33. data set 1650 = 33 \\(\\times\\) survey_size rows.proportions residence vary survey survey? Now must group residence replicate.numbers vary replicate replicate every survey replicate different students drawn random. Let‚Äôs look distribution proportions histogram.frequent proportions rural around 40% urban around 60%. chosen binwidth = 0.05, .e.¬†width columns 5%, can precise. Among surveyed students, 35‚Äì40% live countryside 55‚Äì60% town.","code":"\nlibrary(tidyverse)\nlibrary(infer)\nset.seed(123)\n\nstudent_id <- 1:12000\n  \ntravel_time <- c(runif(n = 12000 * 0.8, min = 5, max = 40),\n             runif(n = 12000 * 0.2, min = 60, max = 120))\n\ngender <- sample(c('m', 'f'), size = 12000, replace = TRUE)\n\nresidence <- sapply(travel_time, function(x) {\n  if(x < 30) 'urban'\n  else 'rural'\n})\n\ntransport <- sapply(travel_time, function(x) {\n  if(x <= 10) 'foot'\n  else if(x > 10 & x <= 15) sample(c('foot', 'bike'), size = 1)\n  else if(x > 15 & x <= 45) sample(c('bus', 'bike', 'car'), size = 1)\n  else sample(c('bus', 'car'), size = 1)\n})\n\ntime_lib <- 5 * 60 - 0.7 * travel_time + rnorm(length(travel_time), 0, 20)\n\ngetsmarter_pop <- tibble(student_id, gender, residence, transport, travel_time, time_lib)\n\ngetsmarter_pop## # A tibble: 12,000 x 6\n##    student_id gender residence transport travel_time time_lib\n##         <int> <chr>  <chr>     <chr>           <dbl>    <dbl>\n##  1          1 f      urban     bus             15.1      294.\n##  2          2 f      rural     bike            32.6      254.\n##  3          3 f      urban     bike            19.3      231.\n##  4          4 m      rural     car             35.9      245.\n##  5          5 m      rural     bus             37.9      234.\n##  6          6 f      urban     foot             6.59     303.\n##  7          7 f      urban     bus             23.5      284.\n##  8          8 m      rural     car             36.2      274.\n##  9          9 m      urban     bike            24.3      299.\n## 10         10 f      urban     bus             21.0      282.\n## # ‚Ä¶ with 11,990 more rows\nset.seed(345)\n\nsurvey_size <- 50\n\nsurvey <- rep_sample_n(getsmarter_pop, size = survey_size, replace = FALSE, reps = 1)\nsurvey## # A tibble: 50 x 7\n## # Groups:   replicate [1]\n##    replicate student_id gender residence transport travel_time time_lib\n##        <int>      <int> <chr>  <chr>     <chr>           <dbl>    <dbl>\n##  1         1       1623 m      urban     foot             7.06     299.\n##  2         1       9171 m      urban     bike            11.3      278.\n##  3         1      10207 f      rural     bus            107.       199.\n##  4         1       3506 f      urban     bus             25.0      326.\n##  5         1       8892 f      urban     bus             28.1      259.\n##  6         1       5460 m      urban     bus             23.6      299.\n##  7         1       6120 f      urban     bus             20.0      268.\n##  8         1        865 f      urban     bike            26.6      290.\n##  9         1      11586 m      rural     bus            114.       207.\n## 10         1       8153 f      urban     foot             8.06     297.\n## # ‚Ä¶ with 40 more rows\nsurvey %>% \n  group_by(residence) %>% \n  count()## # A tibble: 2 x 2\n## # Groups:   residence [2]\n##   residence     n\n##   <chr>     <int>\n## 1 rural        21\n## 2 urban        29\nsurvey %>% \n  group_by(residence) %>% \n  summarise(prop = n()/survey_size)## # A tibble: 2 x 2\n##   residence  prop\n##   <chr>     <dbl>\n## 1 rural      0.42\n## 2 urban      0.58\nset.seed(234)\n\nsurvey_reps <- rep_sample_n(getsmarter_pop, size = survey_size, replace = FALSE, reps = 33)\nsurvey_reps## # A tibble: 1,650 x 7\n## # Groups:   replicate [33]\n##    replicate student_id gender residence transport travel_time time_lib\n##        <int>      <int> <chr>  <chr>     <chr>           <dbl>    <dbl>\n##  1         1       2079 m      rural     car              38.8     262.\n##  2         1       1314 m      urban     bike             13.3     301.\n##  3         1       1710 m      urban     car              26.5     272.\n##  4         1       4386 f      urban     bus              23.9     269.\n##  5         1       9490 m      rural     car              34.2     262.\n##  6         1      11757 f      rural     bus             102.      227.\n##  7         1      11649 f      rural     bus             111.      202.\n##  8         1       2244 m      rural     bus              38.9     256.\n##  9         1       3652 f      urban     bike             10.3     254.\n## 10         1       3127 m      urban     bike             29.6     271.\n## # ‚Ä¶ with 1,640 more rows\nresidence_props <- survey_reps %>% \n  group_by(replicate, residence) %>% \n  summarise(prop = n()/survey_size)\n\nresidence_props## # A tibble: 66 x 3\n## # Groups:   replicate [33]\n##    replicate residence  prop\n##        <int> <chr>     <dbl>\n##  1         1 rural      0.42\n##  2         1 urban      0.58\n##  3         2 rural      0.36\n##  4         2 urban      0.64\n##  5         3 rural      0.4 \n##  6         3 urban      0.6 \n##  7         4 rural      0.38\n##  8         4 urban      0.62\n##  9         5 rural      0.4 \n## 10         5 urban      0.6 \n## # ‚Ä¶ with 56 more rows\nggplot(data = residence_props, aes(x = prop)) + \n  geom_histogram(binwidth = 0.05, boundary = 0.4, col = 'white') +\n  facet_wrap(~ residence) +\n  labs(x = 'Proportion of residence', title = 'Distribution of residences', y = 'Frequency')"},{"path":"sampling.html","id":"number-of-replications-and-variability","chapter":"6 Sampling and variability","heading":"6.2 Number of replications and variability","text":"histograms show proportions residence vary survey survey. 33 large number real life, small number statistics. patterns observe histograms repeat survey 1000 times? use variable reps_num define number repetitions.histograms show now nice symmetrical pattern around 40‚Äì42% rural 58‚Äì60% urban residences. parameter scales = 'free_x' allows scale histogram‚Äôs \\(x\\) axis separately. distribution called sampling distribution. shows distribution possible values statistics (‚Äúproportions residence‚Äù case) one obtains repeated sampling population.statistics ‚Äúproportion residence‚Äù random variable. Every new survey brings new values. sampling distribution can tell us values frequent, .e.¬†probable occur survey students randomly.summarize sampling distribution, can calculate mean value standard deviation. latter special name, standard error.standard errors rural urban identical, dependent: rural = 1 - urban.","code":"\nset.seed(345)\n\nreps_num <- 1000\n\nsurvey_reps <- rep_sample_n(getsmarter_pop, size = survey_size, replace = FALSE, reps = reps_num)\n\nresidence_props <- survey_reps %>% \n  group_by(replicate, residence) %>% \n  summarise(prop = n()/survey_size)\n\nggplot(data = residence_props, aes(x = prop)) + \n  geom_histogram(binwidth = 0.02, boundary = 0.4, col = 'white') +\n  facet_wrap(~ residence, scales = 'free_x') +\n  labs(x = 'Proportion of residence', title = 'Distribution of residences', y = 'Frequency')\nresidence_props %>% \n  group_by(residence) %>% \n  summarise(prop_sd = sd(prop))## # A tibble: 2 x 2\n##   residence prop_sd\n##   <chr>       <dbl>\n## 1 rural      0.0701\n## 2 urban      0.0701"},{"path":"sampling.html","id":"sample-size","chapter":"6 Sampling and variability","heading":"6.3 Sample size","text":"standard error depends sample size. Let‚Äôs repeat survey 25, 50 100 students, respectively observe standard error vary.repetitive tasks like , better define function job instead copy-pasting code vary sample size. difine function without much comments. talk functions later, time allows.Let‚Äôs survey.plot resulting samping distributions.compare standard errors three sampling distributions.see standard error decreases increasing sample size. makes sense larger sample size information contains population, .e.¬†representative. Accordingly, variability information (measured standard error) decreases.time, pre-formulated take-home messages, sampling variability really important topics üòé.\nrandom sample\\(^*\\) can used obtain information larger group, population.\n\nstatistics calculated random sample sometimes called sampling statistics.\n\ndistribution statistics calculated random samples called sampling distribution.\n\nsampling distribution obtained repeated random sampling.\n\nrandom samples drawn, better one can characterize sampling distribution (.e.¬†shape).\n\nstandard error standard deviation sampling statistics.\n\nstandard error decreases increasing sample size.\n\\(^*\\) Sometimes, random sampling appropriate stratified sampling complex sampling designs used. case, subgroups different properties relevant sampling, statistics exist population. However, topic beyond scope course.","code":"\ncalculate_props <- function(population = getsmarter_pop, survey_size, reps_num = 1000) {\n  \n  survey <- rep_sample_n(population, size = survey_size, replace = FALSE, reps = reps_num)\n\nresidence_props <- survey %>% \n  group_by(replicate, residence) %>% \n  summarise(prop = n()/survey_size)\n\nresidence_props\n}\nset.seed(123)\n\n# Sample size 25\nresidence_props_25 <- calculate_props(population = getsmarter_pop, survey_size = 25, reps_num = 1000)\n  \n# Sample size 50\nresidence_props_50 <- calculate_props(population = getsmarter_pop, survey_size = 50, reps_num = 1000)\n\n# Sample size 100\nresidence_props_100 <- calculate_props(population = getsmarter_pop, survey_size = 100, reps_num = 1000)\nggplot(data = residence_props_25, aes(x = prop)) + \n  geom_histogram(binwidth = 0.05, boundary = 0.4, col = 'white') +\n  facet_wrap(~ residence, scales = 'free_x') +\n  labs(x = 'Proportion of residence', title = 'Distribution of residences, sample size = 25', y = 'Frequency')\nggplot(data = residence_props_50, aes(x = prop)) + \n  geom_histogram(binwidth = 0.02, boundary = 0.4, col = 'white') +\n  facet_wrap(~ residence, scales = 'free_x') +\n  labs(x = 'Proportion of residence', title = 'Distribution of residences, sample size = 50', y = 'Frequency')\nggplot(data = residence_props_100, aes(x = prop)) + \n  geom_histogram(binwidth = 0.02, boundary = 0.4, col = 'white') +\n  facet_wrap(~ residence, scales = 'free_x') +\n  labs(x = 'Proportion of residence', title = 'Distribution of residences, sample size = 100', y = 'Frequency')\nresidence_props_25 %>% \n  group_by(residence) %>% \n  summarise(prop_sd = sd(prop))## # A tibble: 2 x 2\n##   residence prop_sd\n##   <chr>       <dbl>\n## 1 rural       0.102\n## 2 urban       0.102\nresidence_props_50 %>% \n  group_by(residence) %>% \n  summarise(prop_sd = sd(prop))## # A tibble: 2 x 2\n##   residence prop_sd\n##   <chr>       <dbl>\n## 1 rural      0.0679\n## 2 urban      0.0679\nresidence_props_100 %>% \n  group_by(residence) %>% \n  summarise(prop_sd = sd(prop))## # A tibble: 2 x 2\n##   residence prop_sd\n##   <chr>       <dbl>\n## 1 rural      0.0458\n## 2 urban      0.0458"},{"path":"sampling.html","id":"practice-on-your-own-5","chapter":"6 Sampling and variability","heading":"6.4 Practice on your own!","text":"large proportions rural urban population students getsmarter. large mean values sampling distributions sample sizes 25, 50 100. Compare figures population parameters comment.large proportions rural urban population students getsmarter. large mean values sampling distributions sample sizes 25, 50 100. Compare figures population parameters comment.student representatives like see students using bike bus instead car. first step, need know many students actually use car.\n\nConduct repeated survey (1000 repetitions) 50 students estimate proportion people using car. large standard error proportion? Compare proportion population. Hint: calculate mean proportions estimated 1000 replicates, use ungroup() delete grouping replicates.student representatives like see students using bike bus instead car. first step, need know many students actually use car.\n\nConduct repeated survey (1000 repetitions) 50 students estimate proportion people using car. large standard error proportion? Compare proportion population. Hint: calculate mean proportions estimated 1000 replicates, use ungroup() delete grouping replicates.","code":""},{"path":"sampling.html","id":"reading-assignment-4","chapter":"6 Sampling and variability","heading":"6.5 Reading assignment","text":"Chapter 7 Ismay Kim (2021)","code":""},{"path":"sampling.html","id":"turning-in-your-work-4","chapter":"6 Sampling and variability","heading":"6.6 Turning in your work","text":"Save R Notebook download .Rmd file computer. don‚Äôt need download .nb.html file.Upload R Notebook ILIAS. find upload option today‚Äôs session.receive solution file submission.\nsure upload deadline!\n","code":""},{"path":"bootstrap.html","id":"bootstrap","chapter":"7 Bootstrap and confidence intervals","heading":"7 Bootstrap and confidence intervals","text":"\nExplain idea behind bootstrap\n\nCalculate bootstrap confidence intervals mean\nchapter 6 studied variability repeated random sampling population. computer experiments sampled form simulated population repeatedly without replacement (.e.¬†data appear sample ) calculated statistics, proportion rural urban residents. statistics random variable characterized sampling distribution. shows values can expect randomly sampling population.learned shape sampling distribution size standard error depended sample size. chapter learn quantify standard error calculate plausible values (confidence intervals) real-life applications, one sample .","code":""},{"path":"bootstrap.html","id":"the-formulas","chapter":"7 Bootstrap and confidence intervals","heading":"7.1 The formulas","text":"never opportunity sample/survey repeatedly estimate information (.e.¬†statistics parameter) population interest. real-life applications one (hopefully cleverly obtained) random sample. can access shape sampling distribution? several standard statistics, formulas describe standard error. probably learned standard error estimated mean equalled \\(\\sigma/\\sqrt(n)\\), \\(\\sigma\\) variance population \\(n\\) sample size. don‚Äôt know variance population, estimate sample . formula come ? important Central Limit Theorem tells us random variable mean can estimate random sample normally distributed mean equalled true mean population standard deviation , guessed , \\(\\sigma/\\sqrt(n)\\). Based normal distribution can calculate plausible values, -called confidence interval. Informally, define confidence interval follows:plausible range values obtain randomly sample population? Plausible means repeated sampling often, range contain true mean let‚Äôs say 95% time. plausible range called 95% confidence interval.know theoretical distribution mean can calculate 95% confidence interval \\(\\hat\\mu \\pm 1.96 \\cdot SE\\), \\(\\hat\\mu\\) estimated mean, \\(SE\\) standard error \\(\\sigma/\\sqrt(n)\\) magic factor 1.96 comes fact normal distribution, 95% values fall interval \\(\\mu \\pm 1.96 \\cdot sd\\), \\(sd\\) standard deviation.","code":""},{"path":"bootstrap.html","id":"bootstrapuse-your-computer","chapter":"7 Bootstrap and confidence intervals","heading":"7.2 Bootstrap‚Äìuse your computer","text":"Formulas date early time statistics computational power limited unavailable approximations tools one use estimate variability. Central Limit Theorem useful, theoretical distributions always exist. cases, can use computer calculate confidence intervals using re-sampling, .e.¬†repeated sampling random sample. method called bootstrap (bootstrapping) sounds like self-deception √† la Baron Munchausen first glance (Figure 7.1). However, solid mathematical foundation (Efron 1979).\nFigure 7.1: M√ºnchhausen removes swamp using braids (Theodor Hosemann (1807-1875), Public domain, via Wikimedia Commons) Link figure\nFigure 7.2 shows setup practiced chapter 6. wanted estimate parameter (proportion rural urban residents) called \\(\\mu\\) figure sampled randomly several times population. random samples calculated statistics obtained sampling distribution.\nFigure 7.2: Calculation sampling distribution repeated random sampling population. Figure Hesterberg (2015), Figure 4. publication open-access can used non-commercial purposes. Link licence\nFigure 7.3 looks basically , except one important difference. don‚Äôt access several random samples population, one random sample . now remember invested time energy thinking best way obtain sample believe representative population. Thus, can think sample mini population. replace population miniature, .e.¬†sample, sample sample true population. However, sample limited size sample replacement. random samples obtain sampling replacement original random sample called bootstrap samples. bootstrap samples calculate statistics obtain bootstrap sampling distribution. confidence interval often calculated -called percentile method: take 2.5% quantile 97.5% quantile sampling distribution. range values -equals 95% bootstrap confidence interval.\nFigure 7.3: Calculation sampling distribution repeated random sampling replacement sample. Figure Hesterberg (2015), Figure 5. publication open-access can used non-commercial purposes. Link licence\n","code":""},{"path":"bootstrap.html","id":"cofidence-intervals-for-the-mean-travel-time","chapter":"7 Bootstrap and confidence intervals","heading":"7.3 Cofidence intervals for the mean travel time","text":"Let‚Äôs come back simulated getsmarter university population estimate mean travel time bootstrap confidence interval.survey 200 students.true mean travel time university mean survey equalTo calculate bootstrap distribution, sample data set survey replacement. size bootstrap samples always equal size original sample. use function rep_sample_n chapter 6, change replace = TRUE.sample replacement, students can now appear several times one bootstrap sample. Let‚Äôs check first 50 bootstrap samples. Student 4787 sampled 8 times replicate 43, example.Now can calculate mean travel times bootstrap samples.standard error 95% confidence interval based bootstrap calculated follows:","code":"\nlibrary(tidyverse)\nlibrary(infer)\nset.seed(123)\n\nstudent_id <- 1:12000\n  \ntravel_time <- c(runif(n = 12000 * 0.8, min = 5, max = 40),\n             runif(n = 12000 * 0.2, min = 60, max = 120))\n\ngender <- sample(c('m', 'f'), size = 12000, replace = TRUE)\n\nresidence <- sapply(travel_time, function(x) {\n  if(x < 30) 'urban'\n  else 'rural'\n})\n\ntransport <- sapply(travel_time, function(x) {\n  if(x <= 10) 'foot'\n  else if(x > 10 & x <= 15) sample(c('foot', 'bike'), size = 1)\n  else if(x > 15 & x <= 45) sample(c('bus', 'bike', 'car'), size = 1)\n  else sample(c('bus', 'car'), size = 1)\n})\n\ntime_lib <- 5 * 60 - 0.7 * travel_time + rnorm(length(travel_time), 0, 20)\n\ngetsmarter_pop <- tibble(student_id, gender, residence, transport, travel_time, time_lib)\n\ngetsmarter_pop## # A tibble: 12,000 x 6\n##    student_id gender residence transport travel_time time_lib\n##         <int> <chr>  <chr>     <chr>           <dbl>    <dbl>\n##  1          1 f      urban     bus             15.1      294.\n##  2          2 f      rural     bike            32.6      254.\n##  3          3 f      urban     bike            19.3      231.\n##  4          4 m      rural     car             35.9      245.\n##  5          5 m      rural     bus             37.9      234.\n##  6          6 f      urban     foot             6.59     303.\n##  7          7 f      urban     bus             23.5      284.\n##  8          8 m      rural     car             36.2      274.\n##  9          9 m      urban     bike            24.3      299.\n## 10         10 f      urban     bus             21.0      282.\n## # ‚Ä¶ with 11,990 more rows\nset.seed(345)\n\nsurvey_size <- 200\n\nsurvey <- rep_sample_n(getsmarter_pop, size = survey_size, replace = FALSE, reps = 1)\nmean_pop <- getsmarter_pop %>% \n  summarise(mean = mean(travel_time))\n\nmean_pop## # A tibble: 1 x 1\n##    mean\n##   <dbl>\n## 1  36.0\nmean_survey <- survey %>% \n  summarise(mean = mean(travel_time))\n\nmean_survey## # A tibble: 1 x 2\n##   replicate  mean\n##       <int> <dbl>\n## 1         1  34.1\nset.seed(345)\n\nreps_num <- 10000\n\nsurvey_reps_bootstrap <- rep_sample_n(survey, size = survey_size, replace = TRUE, reps = reps_num)\n\nsurvey_reps_bootstrap## # A tibble: 2,000,000 x 7\n## # Groups:   replicate [10,000]\n##    replicate student_id gender residence transport travel_time time_lib\n##        <int>      <int> <chr>  <chr>     <chr>           <dbl>    <dbl>\n##  1         1       7038 m      urban     bus             29.4      243.\n##  2         1        493 m      urban     bus             21.1      303.\n##  3         1       3442 m      rural     car             30.3      311.\n##  4         1       4920 f      urban     bus             21.1      290.\n##  5         1       3178 f      urban     foot             8.07     325.\n##  6         1       7694 f      rural     car             31.3      295.\n##  7         1       9479 m      rural     bus             39.5      302.\n##  8         1       3367 m      rural     car             36.4      272.\n##  9         1       5985 f      urban     bike            15.9      303.\n## 10         1        843 m      urban     bike            26.4      300.\n## # ‚Ä¶ with 1,999,990 more rows\nsurvey_reps_bootstrap %>% \n  filter(replicate %in% (1:50)) %>% \n  group_by(replicate, student_id) %>% \n  tally() %>% \n  filter(n != 1) %>% \n  arrange(desc(n))## # A tibble: 2,657 x 3\n## # Groups:   replicate [50]\n##    replicate student_id     n\n##        <int>      <int> <int>\n##  1        43       4787     8\n##  2        20       5985     6\n##  3        34       7749     6\n##  4        38       5641     6\n##  5        41       8456     6\n##  6         3       7083     5\n##  7         3      10943     5\n##  8         5       8994     5\n##  9         6      10118     5\n## 10         8      11425     5\n## # ‚Ä¶ with 2,647 more rows\nres_means_bootstrap <- survey_reps_bootstrap %>%\n  group_by(replicate) %>% \n  summarise(mean_tt = mean(travel_time))\n\nres_means_bootstrap## # A tibble: 10,000 x 2\n##    replicate mean_tt\n##        <int>   <dbl>\n##  1         1    32.6\n##  2         2    31.9\n##  3         3    38.9\n##  4         4    33.5\n##  5         5    35.4\n##  6         6    37.2\n##  7         7    34.4\n##  8         8    33.4\n##  9         9    35.5\n## 10        10    31.0\n## # ‚Ä¶ with 9,990 more rows\nstat_bootstrap <- res_means_bootstrap %>% \n  summarize(mean_bootstrap = mean(mean_tt), se = sd(mean_tt), ci_2.5 = quantile(mean_tt, probs = 0.025), ci_97.5 = quantile(mean_tt, probs = 0.975))\n\nstat_bootstrap## # A tibble: 1 x 4\n##   mean_bootstrap    se ci_2.5 ci_97.5\n##            <dbl> <dbl>  <dbl>   <dbl>\n## 1           34.1  2.06   30.1    38.3"},{"path":"bootstrap.html","id":"bootstrap-with-the-library-infer","chapter":"7 Bootstrap and confidence intervals","heading":"7.4 Bootstrap with the library infer","text":"library infer offers convenient framework calculating bootstrap confidence intervals hypothesis tests. talk latter later session. infer dedicated package tidy inference organised around 5 verbs:specify() variables relationships themhypothesize() define null hypothesis (hypothesis tests )generate() generate data either confidence intervals null hypothesiscalculate() sampling distributionvisualize() visualize sampling distributionHow example calculating bootstrap confidence intervals mean travel time look like infer workflow?first calculate bootstrap distribution., calculate confidence intervals based percentile method.visualize results. function visualize based ggplot, can add custom axis labels.","code":"\nset.seed(345)\n\nbootstrap_distribution <- survey %>%\n  specify(response = travel_time) %>% \n  generate(reps = 10000, type = 'bootstrap') %>% \n  calculate(stat = 'mean')\npercentile_ci <- bootstrap_distribution %>% \n  get_confidence_interval(level = 0.95, type = \"percentile\")\npercentile_ci## # A tibble: 1 x 2\n##   lower_ci upper_ci\n##      <dbl>    <dbl>\n## 1     30.1     38.3\nvisualize(bootstrap_distribution) + \n  shade_confidence_interval(endpoints = percentile_ci, color = \"orange\", fill = \"khaki\") +\n  geom_vline(xintercept = mean_pop$mean, linetype = 'dashed') +\n  labs(x = 'Mean trave time (min)', y = 'Frequency')"},{"path":"bootstrap.html","id":"interpreting-the-confidence-intervals","chapter":"7 Bootstrap and confidence intervals","heading":"7.5 Interpreting the confidence intervals","text":"upper lower limit confidence interval depend sample, .e.¬†random variables. Definitely, random variables everywhere üòÑ. means confidence interval fail include true population parameter. now ready formal definition confidence interval:repeat sampling often recalculate 95% confidence intervals, expect contain true population parameters 95% time.means confidence intervals won‚Äôt contain true population parameter.confidence interval best guess plausible values population parameter. case theoretical distribution statistics, bootstrap theoretical confidence intervals coincide. Often, interpretation short-handed : 95% confident confidence interval captures true parameter. incorrect. better state 95% time, confidence interval captures true population parameter. now know meant ‚Äú95% time‚Äù üòÑ.","code":""},{"path":"bootstrap.html","id":"practice-on-your-own-6","chapter":"7 Bootstrap and confidence intervals","heading":"7.6 Practice on your own!","text":"Repeat analysis mean travel time now proportion urban residents. Use workflow infer. Hint: specify(response = residence, success = 'urban').Repeat analysis mean travel time now proportion urban residents. Use workflow infer. Hint: specify(response = residence, success = 'urban').width confidence interval depend sample size? Repeat analysis mean travel time survey 30 students. Hint: specify(response = wohnort, success = 'stadt').width confidence interval depend sample size? Repeat analysis mean travel time survey 30 students. Hint: specify(response = wohnort, success = 'stadt').","code":""},{"path":"bootstrap.html","id":"reading-assignment-5","chapter":"7 Bootstrap and confidence intervals","heading":"7.7 Reading assignment","text":"Chapter 8 Ismay Kim (2021)","code":""},{"path":"bootstrap.html","id":"turning-in-your-work-5","chapter":"7 Bootstrap and confidence intervals","heading":"7.8 Turning in your work","text":"Save R Notebook download .Rmd file computer. don‚Äôt need download .nb.html file.Upload R Notebook ILIAS. find upload option today‚Äôs session.receive solution file submission.\nsure upload deadline!\n","code":""},{"path":"hypothesis.html","id":"hypothesis","chapter":"8 Hypothesis tests versus effect size estimation","heading":"8 Hypothesis tests versus effect size estimation","text":"\nExplain idea behind simulation-based hypothesis tests\n\nCalculate hypothesis tests infer\n\nExplain difference test effect size estimation\nchapter 7 learned calculate confidence intervals, range plausible values. formally, interval expect contain true population parameters 95% time, repeat sampling often. chapter learn hypothesis tests often better estimate effect sizes.","code":""},{"path":"hypothesis.html","id":"hypothesis-tests-with-infer","chapter":"8 Hypothesis tests versus effect size estimation","heading":"8.1 Hypothesis tests with infer","text":"Let‚Äôs start old study done 1970. Rosen Jerdee (1974) analysed whether ‚Äúsex role stereotypes [] influence personnel decisions.‚Äù modern language, wanted know whether women discriminated promotion decisions. asked 95 bank supervisors decide based personal file whether person promoted . files identical except gender files distributed randomly participants. random assignement files, procedure experiment can draw conclusions research question. , look one part data, namely promotion decision simple job (c.f. original publication details.)Let‚Äôs plot data analyse .large difference proportions promotions men women? difference due chance women discriminated ?hypothesis test helps decide whether observed effect, case difference proportions promotions, can attributed chance. hypothesis test, two different statements contrasted, null hypothesis alternative hypothesis:Statement 1: real difference, observed difference due chance.H\\(_0\\): Null hypothesis. variables gender decision independent; observed difference promotions random.Statement 2: Women discriminated .H\\(_A\\): Alternative hypothesis. variables gender decision dependent. Women discriminated decisions promotion.use general framework package infer hypothesis tests. offers state---art simulation-based approach based following steps (Figure 8.1):specify() variables relationships themhypothesize() define null hypothesisgenerate() generate data null hypothesiscalculate() sampling distribution null hypothesisvisualize() visualize sampling distribution null hypothesisTwo additional functions, shade_p_value get_p_value visualize calculate \\(p\\) value (see definition), respectively.\nFigure 8.1: General framework infer. (Source: https://infer.netlify.app/).\nLet‚Äôs proceed step step. First, calculate observed difference data using infer. parameter order = c(\"male\", \"female\") tells us calculate difference male - female.observe 29.2% less women promoted men.Let‚Äôs see whether difference can attributed chance. generate data null hypothesis, .e.¬†world gender decision promote completely independent. compare data obtain world observed 29.2% difference men women.generate data null hypotheses permutation. means gender decision unrelated observed combinations . Therefore, permuted combination agreement null hypothesis independence variables. generate 10000 permuted samples.object null_distn contains 10000 differences proportions promotion permuted data. can visualize distribution highlight observed difference compare. parameter direction = \"greater\" defines alternative hypothesis women discriminated , .e.¬†difference larger zero. function shade_p_value shades values larger observed statistics. red bar shows observed statistic .\\(p\\) value probability obtain data extreme extreme observed, null hypothesis true.\\(p\\) value example equalsThis \\(p\\) value really small. rare observe difference larger 29.2%, assume women men promoted equally often. reject null hypothesis independence conclude women discriminated promotion. cautionary note: experiment, assumed participating bank supervisors representative profession 1970s. Thus, cautious conclude women discriminated 1970 (provided white male bank supervisors representative -population decision-makers).","code":"\nlibrary(tidyverse)\nlibrary(infer)\nlibrary(knitr)\nstudy <- tibble('gender' = c(rep('male', 24),\n                             rep('female', 24)),\n                'decision' = c(rep('promoted', 21),\n                               rep('not_promoted', 3),\n                               rep('promoted', 14),\n                               rep('not_promoted', 10)))\n\nstudy %>% \n  table() %>% \n  addmargins() %>% \n  kable()\nggplot(study, aes(x = gender, fill = decision)) +\n  geom_bar() +\n  labs(x = 'Gender on personal file', y = 'Abs. frequency',\n       title = 'Decisions of bank supervisors from study by Rosen & Jerdee (1974)')\nprop_hat <- study %>% \n  specify(formula = decision ~ gender, success = \"promoted\") %>%\n  calculate(stat = \"diff in props\", order = c(\"male\", \"female\"))\n\nprop_hat## # A tibble: 1 x 1\n##    stat\n##   <dbl>\n## 1 0.292\nset.seed(123)\n\nnull_distn <- study %>%\n  specify(formula = decision ~ gender, success = \"promoted\") %>%\n  hypothesize(null = \"independence\") %>% \n  generate(reps = 10000) %>% \n  calculate(stat = \"diff in props\", order = c(\"male\", \"female\"))## Setting `type = \"permute\"` in `generate()`.\nnull_distn## # A tibble: 10,000 x 2\n##    replicate    stat\n##        <int>   <dbl>\n##  1         1  0.125 \n##  2         2  0.292 \n##  3         3 -0.0417\n##  4         4 -0.0417\n##  5         5 -0.125 \n##  6         6 -0.0417\n##  7         7  0.0417\n##  8         8  0.0417\n##  9         9  0.0417\n## 10        10  0.0417\n## # ‚Ä¶ with 9,990 more rows\nvisualize(null_distn, bins = 12) +\n  shade_p_value(obs_stat = prop_hat, direction = \"greater\")\nnull_distn %>% \n  get_p_value(obs_stat = prop_hat, direction = 'greater')## # A tibble: 1 x 1\n##   p_value\n##     <dbl>\n## 1  0.0268"},{"path":"hypothesis.html","id":"there-is-only-one-test","chapter":"8 Hypothesis tests versus effect size estimation","heading":"8.2 There is only one test!","text":"read literature, find lot different tests. difficult keep names remember use . good news unnecessary complicated can simplified test procedure based computer simulations infer. general logic behind simulation-based tests shown Figure 8.2.\nFigure 8.2: General logic behind simulation-based hypothesis test. (Source: http://allendowney.blogspot.com/2016/06/--still--one-test.html. Used permission author Prof.¬†Allen Downey).\ntest procedure based steps, regardless test want apply.Step 1: calculate test statistic data\nSummarize data test statistic. can mean difference proportions. Figure 8.2 statistic called \\(\\sigma*\\).Step 2: formulate null hypothesis\nThink research question. want know? Derive model world effect absent. null hypothesis \\(H_0\\). model can permutation variables theoretical model complicated model üòÑ.Step 3: generate data null hypothesis\nGenerate data, .e.¬†many data samples, using model \\(H_0\\) calculate statistic observed data samples.Step 4: calculate sampling distribution\nstatistics null give sampling distribution can visualize. Additionally, visualize observed statistic \\(\\sigma*\\) compare. value appear often sampling distribution rare? \\(p\\) value gives frequency often sampling distribution values least large \\(\\sigma*\\).Step 5: Decide!\n\\(p\\) values small? Use domain knowledge frame result. need refer statistical significance ! Formulate conclusion plain language. Think obtained data. always uncertainty, modest overstate finding!much say misuse \\(p\\) values term ‚Äústatistical significance.‚Äù good starting point paper Wasserstein, Schirm, Lazar (2019).","code":""},{"path":"hypothesis.html","id":"hypothesis-test-versus-effect-size-estimation","chapter":"8 Hypothesis tests versus effect size estimation","heading":"8.3 Hypothesis test versus effect size estimation","text":"Compared statistical test, estimation called effect size can much interesting. Effect size can difference means proportions elaborated (standardized) effects. statistical test gives ‚Äúfeeling‚Äù whether observed effect attributed chance, estimation effect size confidence intervals gives range plausible values. much interesting relevant discuss mean real life just state something () due chance. Prefer effect size confidence intervals possible hypothesis tests.","code":""},{"path":"hypothesis.html","id":"practice-on-your-own-7","chapter":"8 Hypothesis tests versus effect size estimation","heading":"8.4 Practice on your own!","text":"travel time time spent library correlate getsmarter population? statistical test based survey 200 students. Formulate null alternative hypothesis test. Hint: specify(travel_time ~ time_lib) calculate(stat = \"correlation\"). Consult web site library infer (c.f. ).travel time time spent library correlate getsmarter population? statistical test based survey 200 students. Formulate null alternative hypothesis test. Hint: specify(travel_time ~ time_lib) calculate(stat = \"correlation\"). Consult web site library infer (c.f. ).travel time time spent library correlate getsmarter population? time, estimate correlation calculate confidence interval. Compare hypothesis test.travel time time spent library correlate getsmarter population? time, estimate correlation calculate confidence interval. Compare hypothesis test.","code":""},{"path":"hypothesis.html","id":"reading-assignment-6","chapter":"8 Hypothesis tests versus effect size estimation","heading":"8.5 Reading assignment","text":"Chapter 9 Ismay Kim (2021)","code":""},{"path":"hypothesis.html","id":"additional-resources","chapter":"8 Hypothesis tests versus effect size estimation","heading":"8.6 Additional resources","text":"Webpage infer: https://infer.netlify.app/Great talk author infer.","code":""},{"path":"hypothesis.html","id":"turning-in-your-work-6","chapter":"8 Hypothesis tests versus effect size estimation","heading":"8.7 Turning in your work","text":"Save R Notebook download .Rmd file computer. don‚Äôt need download .nb.html file.Upload R Notebook ILIAS. find upload option today‚Äôs session.receive solution file submission.\nsure upload deadline!\n","code":""},{"path":"lin-reg.html","id":"lin-reg","chapter":"9 Linear regression","heading":"9 Linear regression","text":"\nExplain general structure linear model.\n\nName assumption linear model.\n\nCalculate simple linear regression R.\nchapter, start journey statistical modelling. Basically, two main reasons one like build statistical model.Explicative modelling: suppose relationship variables like quantify .Predictive modelling: want build model can (accurately possible) predict future values.course, focus explicative modelling work linear regression models.","code":""},{"path":"lin-reg.html","id":"what-is-a-linear-regression-model","chapter":"9 Linear regression","heading":"9.1 What is a linear regression model?","text":"term regression coined Francis Galton (1822-1911) studied relationship height parents children (Fahrmeir, Kneib, Lang 2009). showed taller--average parents tended children smaller parents (towards average) smaller--average parents tended taller children. called phenomenon regression towards mean.regression model estimates relationship dependent variable, often called \\(y\\) independent variables (predictors) often termed \\(X\\). Note capital letter \\(X\\) indicate can collection independent variables (matrix). try definition:\nregression model form:\n\n\\[y = f(X) + \\varepsilon\\]\n\n\\(y\\): dependent variable\n\n\\(f\\): type relationship (function)\n\n\\(X\\): independent variables (predictors, explanatory variables)\n\n\\(\\varepsilon\\): error term\n\n:\n\n\\(f\\) linear (effect predictors additive), model called linear regression model\n\n\\(X\\) single predictor, model called simple linear regression model, otherwise multiple linear regression model\n\nComponents model:\n\n\\(f(X)\\): systematic deterministic component\n\n\\(\\varepsilon\\): stochastic component (error term, residuals)\nregression model, exact values dependent variable, systematic influence predictors mean value dependent variable. error term (can contain random fluctuations, measurement errors etc.), dependent variable \\(y\\) random variable.","code":""},{"path":"lin-reg.html","id":"simple-linear-regression","chapter":"9 Linear regression","heading":"9.2 Simple linear regression","text":"case one predictor , model simple linear regression model geometric form line. line defined intercept (point cuts \\(y\\) axis) slope. exactly form simple linear regression model:\nGiven data pairs: \\((y_i,x_i), \\quad =1,\\dots,n\\)\n\n\\(y\\) \\(x\\) numeric variables.\n\ncall model \\[y_i=\\beta_0 + \\beta_1x_i + \\varepsilon_i, \\qquad =1,\\dots,n.\\]\n\nsimple linear regression model, errors \\(\\varepsilon_1,\\dots, \\varepsilon_n\\) independent identically distributed (iid) \n\n\\[\\mathrm{E}(\\varepsilon_i) = 0, \\qquad \\mathrm{Var}(\\varepsilon_i)=\\sigma^2.\\]\n\nadditionally \\[\\varepsilon_i \\sim N(0,\\sigma^2)\\]\n\n.e.¬†residuals normally distributed, call model normal linear regression model.\n\n\\(\\beta_0\\) intercept \\(\\beta_1\\) slope model.\nassumptions normal linear regression model can summarized LINE:Linear relationship variablesIndependence residualsNormal residualsEquality variance (called homoscedasticity) mean zero residualsBefore look model results, confidence intervals slope intercept, ensure assumptions met!","code":""},{"path":"lin-reg.html","id":"example-relationship-between-the-time-in-the-library-and-the-travel-time","chapter":"9 Linear regression","heading":"9.3 Example: Relationship between the time in the library and the travel time","text":"come back lovely getsmarter university want study relationship time student needs come university time spends library.Let‚Äôs generate population.survey 200 students.","code":"\nlibrary(tidyverse)\nlibrary(infer)\nlibrary(moderndive)\nlibrary(knitr)\nset.seed(123)\n\nstudent_id <- 1:12000\n  \ntravel_time <- c(runif(n = 12000 * 0.8, min = 5, max = 40),\n             runif(n = 12000 * 0.2, min = 60, max = 120))\n\ngender <- sample(c('m', 'f'), size = 12000, replace = TRUE)\n\nresidence <- sapply(travel_time, function(x) {\n  if(x < 30) 'urban'\n  else 'rural'\n})\n\ntransport <- sapply(travel_time, function(x) {\n  if(x <= 10) 'foot'\n  else if(x > 10 & x <= 15) sample(c('foot', 'bike'), size = 1)\n  else if(x > 15 & x <= 45) sample(c('bus', 'bike', 'car'), size = 1)\n  else sample(c('bus', 'car'), size = 1)\n})\n\ntime_lib <- 5 * 60 - 0.7 * travel_time + rnorm(length(travel_time), 0, 20)\n\ngetsmarter_pop <- tibble(student_id, gender, residence, transport, travel_time, time_lib)\n\ngetsmarter_pop## # A tibble: 12,000 x 6\n##    student_id gender residence transport travel_time time_lib\n##         <int> <chr>  <chr>     <chr>           <dbl>    <dbl>\n##  1          1 f      urban     bus             15.1      294.\n##  2          2 f      rural     bike            32.6      254.\n##  3          3 f      urban     bike            19.3      231.\n##  4          4 m      rural     car             35.9      245.\n##  5          5 m      rural     bus             37.9      234.\n##  6          6 f      urban     foot             6.59     303.\n##  7          7 f      urban     bus             23.5      284.\n##  8          8 m      rural     car             36.2      274.\n##  9          9 m      urban     bike            24.3      299.\n## 10         10 f      urban     bus             21.0      282.\n## # ‚Ä¶ with 11,990 more rows\nset.seed(345)\n\nsurvey_size <- 200\n\nsurvey <- rep_sample_n(getsmarter_pop, size = survey_size, replace = FALSE, reps = 1)"},{"path":"lin-reg.html","id":"fit-a-simple-normal-regression-model","chapter":"9 Linear regression","heading":"9.3.1 Fit a simple normal regression model","text":"first check linear model makes sense relationship two variables (approximately) linear.looks reasonably linear can proceed modelling.fit linear model R, use function lm(). dependent independent varialbes joined formula tilde sign ~. can also omit word formula just type time_lib ~ travel_time.‚Äôs üòÑ.Let‚Äôs look estimated intercept slope. function get_regression_table provides tidy form model results function kable() layouts nicely.estimated intercept equals 302.094 minutes slope -0.766 minutes, respectively. can write model :\\[\\widehat{\\text{time_lib}_i} = 302.094 - 0.766 \\cdot \\text{travel_time}_i + \\varepsilon_i\\]\nmodel estimates time_lib value every student \\(\\), \\(\\) arbitrary student index running 1 200 surveyed 200 students. ‚Äúhat‚Äù \\(\\text{time_lib}_i\\) indicates estimate. estimated time library systematic component model, namely \\(302.094 - 0.766 \\cdot \\text{travel_time}_i\\). difference actual time library estimated value error term residuum \\(\\varepsilon_i\\).simplify analysis, put original data, estimated values (also called fitted values) residuals one tibble. respective values can extracted model object lin_mod functions fitted() residuals().Let‚Äôs look residuals fitted values.","code":"\nggplot(data = survey, aes(x = travel_time, y = time_lib)) +\n  geom_point() +\n  labs(x = 'Travel time (min)', y = 'Time in the library (min)')\nlin_mod <- lm(formula = time_lib ~ travel_time, data = survey)\nget_regression_table(lin_mod) %>% kable()\nmodel_res <- survey %>%\n  mutate(fitted = fitted(lin_mod), residuals = residuals(lin_mod))\n\nmodel_res## # A tibble: 200 x 9\n## # Groups:   replicate [1]\n##    replicate student_id gender residence transport travel_time time_lib fitted\n##        <int>      <int> <chr>  <chr>     <chr>           <dbl>    <dbl>  <dbl>\n##  1         1       1623 m      urban     foot             7.06     299.   297.\n##  2         1       9171 m      urban     bike            11.3      278.   293.\n##  3         1      10207 f      rural     bus            107.       199.   220.\n##  4         1       3506 f      urban     bus             25.0      326.   283.\n##  5         1       8892 f      urban     bus             28.1      259.   281.\n##  6         1       5460 m      urban     bus             23.6      299.   284.\n##  7         1       6120 f      urban     bus             20.0      268.   287.\n##  8         1        865 f      urban     bike            26.6      290.   282.\n##  9         1      11586 m      rural     bus            114.       207.   215.\n## 10         1       8153 f      urban     foot             8.06     297.   296.\n## # ‚Ä¶ with 190 more rows, and 1 more variable: residuals <dbl>\nggplot(model_res, aes(x = travel_time, y = time_lib)) +\n  geom_segment(aes(xend = travel_time, yend = fitted, lty = 'Residuals'), alpha = 0.2)  + \n  geom_abline(intercept = coef(lin_mod)[1], slope = coef(lin_mod)[2], color = \"lightblue\") +\n  geom_point(aes(col = 'observed')) +\n  geom_point(aes(y = fitted, col = 'fitted'), shape = 1, size = 2) +\n  labs(x = 'Travel time (min)', y = 'Time in the library (min)') +\n  scale_color_manual(name = '', values = c(observed = 'black', fitted = 'blue'), breaks = c('observed', 'fitted'), label = c('Observed values', 'Fitted values')) +\n  scale_linetype_manual(name = '', values = ('Residuals' = 'solid')) +\n  theme(legend.position = 'bottom')"},{"path":"lin-reg.html","id":"model-assumptions","chapter":"9 Linear regression","heading":"9.3.2 Model assumptions","text":"interpret meaning model parameters intercept slope, check model assumptions. already saw relationship reasonably linear. Let‚Äôs look rest assumptions.Independent residuals. difficult check come study design. like example independently surveyed students, can reasonably assume , data residuals independent. Conversely means use normal linear regression model time depenend data (time series) spatially dependent data. line fit still correct, confidence intervals won‚Äôt.Normal residuals. check normality residuals, use graphical tool, namely -called qq-plot. compares random data normal distribution residuals. data fall strait line (least approximately) can conclude residuals normally distributed.looks good üòÑ. need practice judge qq-plots. need worry see large deviations line small large values.Equal variance zero mean. last assumption, plot residuals versus fitted values. important residuals remain (approximately) equally large small large fitted values fluctuate around zero.slightly larger residuals larger fitted values. However, also larger smaller fitted values (.e.¬†travel times). distorts picture bit. Overall, serious problem .","code":"\nggplot(model_res, aes(sample = residuals)) + \n  stat_qq() + \n  stat_qq_line() +\n  labs(x = 'Quantiles of the normal distribution',\n       y = 'Qauntiles of the residuals')\nggplot(data = model_res, aes(x = fitted, y = residuals)) + \n  geom_point() +\n  geom_hline(yintercept=0, col = 'red') + \n  labs(x = 'Fitted values', y = 'Residuals')"},{"path":"lin-reg.html","id":"interprete-your-model","chapter":"9 Linear regression","heading":"9.3.3 Interprete your model","text":"can conclude model meets assumptions. Therefore, can interpret estimated parameters confidence intervals now.see time student spend library decreases increasing travel time. precisely, travel time increases one minute, time spent library changes -0.8 [-0.9, -0.7]. confidence interval narrow. means estimation precise.Now, need frame result. decrease less minute per minute travel time sounds rather small. However, student needs one hour come university, spends roughly 45 minutes less library. Basically, time spent travelling spent working library. Stated like , result important students‚Äô time management.","code":"\nget_regression_table(lin_mod) %>% kable()"},{"path":"lin-reg.html","id":"practice-on-your-own-8","chapter":"9 Linear regression","heading":"9.4 Practice on your own!","text":"Predictors need numeric. Work Chapter 5.2 Ismay Kim (2021) see example categorical predictor.","code":""},{"path":"lin-reg.html","id":"reading-assignment-7","chapter":"9 Linear regression","heading":"9.5 Reading assignment","text":"Chapter 5 Ismay Kim (2021)","code":""},{"path":"lin-reg-inference.html","id":"lin-reg-inference","chapter":"10 Inference in linear regression","heading":"10 Inference in linear regression","text":"\nCalculate confidence intervals model parameters\n\nInterpret summary linear regression model\n\nUse bootstrap confidence intervals\nlast chapter, learned fit simple linear model. Remember assumptions model:Linear relationship variablesIndependence residualsNormal residualsEquality variance (called homoscedasticity) mean zero residualsIn chapter, see judge quality model. learn case normality homoscedasticity assumptions violated.","code":""},{"path":"lin-reg-inference.html","id":"how-good-is-the-model","chapter":"10 Inference in linear regression","heading":"10.1 How good is the model?","text":"data model certain variability quantify e.g.¬†standard deviation. judge good model captures relationship dependent variable predictors, quantify much variability dependent variable can explained model. Thus, split variability dependent variable :\\[\n\\begin{align*}\n\\mathit{SQT} &= \\mathit{SQE} + \\mathit{SQR}\\\\\n\\sum^{n}_{= 1} (y_i-\\bar{y})^2 &= \\sum^{n}_{=1} (\\hat{y}_i - \\bar{y})^2 + \\sum^{n}_{=1} (y_i - \\hat{y}_i)^2\\\\\n\\end{align*}\n\\]\\(y_i\\): observed data, \\(\\bar{y}\\): mean, \\(\\hat{y}_i\\): fitted values\\(\\mathit{SQT}\\) Sum squares total: variability variance data\\(\\mathit{SQE}\\) Sum squares explained: variability explained model\\(\\mathit{SQR}\\) Sum squares residual: variability explained modelThe \\(\\mathit{SQE}\\) quantifies variability fitted values around mean data \\(\\mathit{SQR}\\) shows much variability model fails capture. smaller residual variability \\(\\mathit{SQR}\\) better model! -called coefficient determination calculates proportion explained variability. larger better model üòÑ:\\[R^2 = \\frac{\\mathit{SQE}}{\\mathit{SQT}} = 1 - \\frac{SQR}{SQT} = 1- \\frac{\\sum^{n}_{=1} (y_i - \\hat{y}_i)^2}{\\sum^{n}_{= 1} (y_i - \\bar{y}_i)^2}\\]Let‚Äôs go back example look coefficient determination.lot information coming summary. details, find:r_squared: Coefficient determination \\(R^2\\)adj_r_squared:\n\\(R^2_\\text{ajd} = 1 - (1 - R^2) \\frac{n-1}{n - p - 1}\\), \\(n\\): number data points, \\(p\\): number predictors (without intercept); robust \\(R^2\\) multiple linear regressionmse: mean standard error mean(residuals(lin_mod)^2)rmse: square root msesimga: standard error error term \\(\\varepsilon\\)statistic: value \\(F\\) statistics hypothesis test, \\(H_0\\): model parameters equal zerop-value: \\(p\\) value hypothesis testdf: degrees freedom, number predictorsnobst: number data pointsThus, conclude hat model explained 53% variance data.","code":"\nlibrary(tidyverse)\nlibrary(infer)\nlibrary(knitr)\nlibrary(moderndive)\nlin_mod <- lm(formula = time_lib ~ travel_time, data = survey)\n\nget_regression_summaries(lin_mod) %>% kable()"},{"path":"lin-reg-inference.html","id":"bootstrap-with-infer-confidence-interval-for-the-slope","chapter":"10 Inference in linear regression","heading":"10.2 Bootstrap with infer: Confidence interval for the slope","text":"case, residuals non-normally distributed /heteroscedastic, confidence intervals model parameters wrong. particular small data sets, violation assumptions problematic. avoid interpreting (possibly) wrong confidence intervals, can use bootstrap construct confidence intervals require normality homoscedasticity residuals. However, still require independent data (always case ordinary bootstrap).simple linear regression, interesting parameter slope. can use usual framework infer determine confidence interval.Step 1: Bootstrap data calculate statistic slopeStep 2: Calculate confidence intervalStep 3: Visualise resultCompared standard confidence interval based normality homoscedasticity assumptions, bootstrap confidence interval similar.model, assumptions valid. case, confidence intervals similar can safely use standard confidence interval. Otherwise prefer bootstrap.","code":"\nbootstrap_distn_slope <- survey %>% \n  specify(formula = time_lib ~ travel_time) %>%\n  generate(reps = 10000, type = \"bootstrap\") %>% \n  calculate(stat = \"slope\")\npercentile_ci <- bootstrap_distn_slope %>% \n  get_confidence_interval(type = \"percentile\", level = 0.95)\n\npercentile_ci## # A tibble: 1 x 2\n##   lower_ci upper_ci\n##      <dbl>    <dbl>\n## 1   -0.848   -0.687\nvisualize(bootstrap_distn_slope) +\n    shade_confidence_interval(endpoints = percentile_ci) \nget_regression_table(lin_mod) %>% \nfilter(term == 'travel_time') %>%\n  kable()"},{"path":"lin-reg-inference.html","id":"practice-on-your-own-9","chapter":"10 Inference in linear regression","heading":"10.3 Practice on your own!","text":"analyse relationship number plant species number endemic species Galapagos islands. data set called gala part library faraway.\nLoad data set read help pages understand meaning variables.\nwant know number endemic species depends number plant species islands. Fit linear regression model takes number species predictor number endemic species dependent variable.\nCheck model assumptions.\nUse workflow infer calculate confidence interval slope model.\nCompare confidence interval based normality assumption bootstrap confidence intervals\nLoad data set read help pages understand meaning variables.want know number endemic species depends number plant species islands. Fit linear regression model takes number species predictor number endemic species dependent variable.Check model assumptions.Use workflow infer calculate confidence interval slope model.Compare confidence interval based normality assumption bootstrap confidence intervals","code":""},{"path":"lin-reg-inference.html","id":"reading-assignment-8","chapter":"10 Inference in linear regression","heading":"10.4 Reading assignment","text":"Chapter 10 Ismay Kim (2021)","code":""},{"path":"lin-reg-inference.html","id":"turning-in-your-work-7","chapter":"10 Inference in linear regression","heading":"10.5 Turning in your work","text":"Save R Notebook download .Rmd file computer. don‚Äôt need download .nb.html file.Upload R Notebook ILIAS. find upload option today‚Äôs session.receive solution file submission.\nsure upload deadline!\n","code":""},{"path":"stat-background.html","id":"stat-background","chapter":"A Statistics refresher","heading":"A Statistics refresher","text":"\nRefresh basic statistics\nchapter short refresher basic statistics replace statistics book. use penguins data set calculate examples.\nFigure .1: Artwork @allison_horst\n","code":"\nlibrary(palmerpenguins)\nlibrary(tidyverse)"},{"path":"stat-background.html","id":"descriptive-statistics","chapter":"A Statistics refresher","heading":"A.1 Descriptive statistics","text":"","code":""},{"path":"stat-background.html","id":"mean","chapter":"A Statistics refresher","heading":"A.1.1 Mean","text":"mean one common summary statistics can calculate data. calculate mean sum values data set divide sum number values.\\[\\bar{x} = \\sum_{= 1}^{= n} \\frac{x_i}{n}\\]\n:\\(\\bar{x}\\): mean value data set \\(x\\)\\(\\): index running 1 \\(n\\), number data (sample size)\\(x_i\\): single data points data sets \\(x\\)simple example first, turn penguins. Let‚Äôs calculate mean data set containing values 2, 4.3, 5 10 hand compare values obtained function mean().expected, values identical. Let‚Äôs now calculate mean bill length penguins.function mean() returns NA missing data data set. Remember exclude NAs get meaningful result.","code":"\na <- c(2, 4.3, 5, 10)\n\nhand_mean = (2 + 4.3 + 5 + 10)/4\nr_mean <- mean(a)\n\nhand_mean## [1] 5.325\nr_mean## [1] 5.325\nmean(x = penguins$bill_length_mm)## [1] NA\nmean(x = penguins$bill_length_mm, na.rm = TRUE)## [1] 43.92193"},{"path":"stat-background.html","id":"standard-deviation","chapter":"A Statistics refresher","heading":"A.1.2 Standard deviation","text":"standard deviation measure variability data. shows far average data deviation mean value. Deviation squared difference data point mean data. standard deviation square root variance defined :\\[s = \\sqrt{\\frac{1}{n-1} \\sum_{= 1}^{= n} (x_i - \\bar{x})^2}\\]\n:\\(\\bar{x}\\): mean value data set \\(x\\)\\(\\): index running 1 \\(n\\), number data (sample size)\\(x_i\\): single data points data sets \\(x\\)large standard deviation data set ? , compare results -hand calculation output function sd()., identical üòÑ. large standard deviation penguins‚Äô bill lengths? Don‚Äôt forget exclude missing values!","code":"\nsd_hand <- sqrt(((2 - r_mean)^2 + (4.3 - r_mean)^2 + (5 - r_mean)^2 + (10 - r_mean)^2)/(4 - 1))\n\nr_sd <- sd(a)\n\nsd_hand## [1] 3.369842\nr_sd## [1] 3.369842\nmean(x = penguins$bill_length_mm, na.rm = TRUE)## [1] 43.92193"},{"path":"stat-background.html","id":"measures-of-association","chapter":"A Statistics refresher","heading":"A.2 Measures of association","text":"","code":""},{"path":"stat-background.html","id":"linear-correlation-coefficent","chapter":"A Statistics refresher","heading":"A.2.1 Linear correlation coefficent","text":"Aka Pearson correlation coefficient Pearson product-moment correlation coefficient measures linear association two numeric variables:\\[ r = \\frac{\\sum_{= 1}^{= n} (x_i - \\bar{x})(y_i - \\bar{y})}{ \\sqrt{\\sum_{= 1}^{= n} (x_i - \\bar{x})^2} \\sqrt{\\sum_{= 1}^{= n} (y_i - \\bar{y})^2}}\\]\n:\\(\\bar{x}\\) \\(\\bar{y}\\): mean values data set \\(x\\) \\(y\\), respectively\\(\\): index running 1 \\(n\\), number data (sample size)\\(x_i\\) \\(y_i\\): single data points data sets \\(x\\) \\(y\\), respectivelyThe Pearson correlation coefficients varies -1 (perfect negative correlation) 1 (perfect positive correlation). value around zero shows linear correlation. However, different kind assiciation might exist data. Remember always plot data!\nFigure .2: Artwork @allison_horst\nneed distinguish species correlations differ .","code":"\nadelie <- penguins %>% \n  filter(species == 'Adelie')\n\ncor(adelie$bill_length_mm, adelie$bill_depth_mm, method = 'pearson', use = 'pairwise.complete.obs')## [1] 0.3914917\nggplot(data = penguins, aes(x = bill_length_mm, y = bill_depth_mm, col = species)) +\n  geom_point() +\n  geom_smooth(se = FALSE, method = lm)"},{"path":"daten-und-bericht.html","id":"daten-und-bericht","chapter":"B Data sources and final report","heading":"B Data sources and final report","text":"\nKnow different data sources\n\nUse libraries direct access databases\n","code":""},{"path":"daten-und-bericht.html","id":"data-sources","chapter":"B Data sources and final report","heading":"B.1 Data sources","text":"chapter, introduce interesting data sources (databases) can use final report. offer technical assistance package eurostat. can discover packages (possible challenge final report, see üòÑ).","code":""},{"path":"daten-und-bericht.html","id":"federal-statistical-office","chapter":"B Data sources and final report","heading":"B.1.1 Federal Statistical Office","text":"Federal Statistical Office offers data Germany different areas database\nGENESIS. can navigate data sets download . Pay attention select format flat downloading get tidy data set.","code":""},{"path":"daten-und-bericht.html","id":"eurostat","chapter":"B Data sources and final report","heading":"B.1.2 eurostat","text":"eurostat statistical office European Union. find many different data sets Europe . However, don‚Äôt need download hand, can use dedicated library eurostat. library informative web site many tutorials. can also use eurostat data visualize maps (possible report challenge).","code":""},{"path":"daten-und-bericht.html","id":"gapminder","chapter":"B Data sources and final report","heading":"B.1.3 gapminder","text":"already worked excerpt data gapminder. complete data set contains much . can download data . gapminder organises data -called DDF Format (data description format) tidy .csv files. possible report challenge understand format. complete data set availagle via GitHub .","code":""},{"path":"daten-und-bericht.html","id":"national-oceanic-and-atmospheric-administration-noaa","chapter":"B Data sources and final report","heading":"B.1.4 National Oceanic and Atmospheric Administration (NOAA)","text":"NOAA offers data oceans, climate weather. can download data sets via library rnoaa.","code":""},{"path":"daten-und-bericht.html","id":"more-data-sources","chapter":"B Data sources and final report","heading":"B.1.5 More data sources","text":"World Bank Open DataWorld Happiness ReportGlobal Carbon Budget 2020\nPublication data set\nGlobal Carbon Project\nPublication data setGlobal Carbon ProjectSoil organic carbon contents sites perennial cultivation\nPublication\nData set\nPublicationData setPANGAEA: eine der gr√∂√üten Datenbanken f√ºr UmweltdatenOverview data libraries ROpenScie:\nData\nLibraries","code":""},{"path":"daten-und-bericht.html","id":"research-proposal","chapter":"B Data sources and final report","heading":"B.2 Research proposal","text":"write final report, need submit research proposal ILIAS. sure upload deadline!. receive feedback . avoid misunderstanding final report. Please use template provided ILIAS research proposal.","code":""},{"path":"daten-und-bericht.html","id":"structure-of-the-final-report","chapter":"B Data sources and final report","heading":"B.3 Structure of the final report","text":"","code":""},{"path":"daten-und-bericht.html","id":"sturcture-of-the-working-directory","chapter":"B Data sources and final report","heading":"B.3.1 Sturcture of the working directory","text":"Create new R project final report. can find using projects . project helps structure work properly.Inside project folder, create folder data, figures (help) scripts (appropriate). Save notebooks root directory project.","code":""},{"path":"daten-und-bericht.html","id":"download-and-save-data","chapter":"B Data sources and final report","heading":"B.3.2 Download and save data","text":"want use libraries download data, create notebook task. Don‚Äôt download analyse data --fly. Data can change time delay analysis assessment report. Download save data data folder. Use saved data analysis.","code":""},{"path":"daten-und-bericht.html","id":"structure-of-the-report","chapter":"B Data sources and final report","heading":"B.3.3 Structure of the report","text":"Please structure report follows:Introduction (research question end)Material Methods: Data description (date download), description method references, description research area appropriateResults: Explorative data analysis, analysis respond research questionDiscussion: use peer-reviewed literature frame resultsConclusionsBibliographyYou can combine results discussion one section.report contain challenge. can extensive data tidying wrangling use new interesting library (e.g.¬†represent spatial data eurostat) etc.can write report groups two, even recommend . case, please add names respective parts responsible . Every part graded separately. Every group member need analysis writing.don‚Äôt impose particular length report. However, concise.Knit final report html-document. Think whether need show chunks, avoid redundancy. Compress whole project submit everything! report analysis must run computer abserve paths!\nSubmit compressed project ILIAS deadline.\n","code":""},{"path":"additional-exercises.html","id":"additional-exercises","chapter":"C Additional exercises","heading":"C Additional exercises","text":"","code":""},{"path":"additional-exercises.html","id":"introduction-to-r-and-rstudio-server-pro","chapter":"C Additional exercises","heading":"C.1 Introduction to R and RStudio Server Pro","text":"","code":""},{"path":"additional-exercises.html","id":"rob1","chapter":"C Additional exercises","heading":"C.1.1 Rob‚Äôs account book","text":"young master student Rob Stat thinks seriously mother‚Äôs advice monitor expenses. begins writing spends week Mensa:\nTable C.1: Rob‚Äôs account book\nGenerate vector Rob‚Äôs expenses assign variable expenses. Use function c() use numeric expenses , days week.much Rob spend week? Use function sum().Rob seems spent smallest amount Tuesday. much spent paid much every day week? Use array notation square brackets.Unfortunately, Rob misspelled amount Tuesday. Actually, invited girl friend lunch paid 7.95 ‚Ç¨ instead 2.90 ‚Ç¨.Correct Rob‚Äôs typo.result change?","code":""},{"path":"additional-exercises.html","id":"rob2","chapter":"C Additional exercises","heading":"C.1.2 Missing values","text":"R codes missing values NA. Rob ate Mensa last Monday, forgot write amount.\nTable C.2: Rob‚Äôs account book, cont.\nNA change calculated sum?Read happens data contains NAs calling help sum, .e.¬†type ?sum R console.Correct call sum() accordingly.","code":""},{"path":"additional-exercises.html","id":"firstplot","chapter":"C Additional exercises","heading":"C.1.3 Your very first plot","text":"particular beginning learning R forget . R really beautiful want analyse learn real data.Even don‚Äôt fully understand following code, just copy paste .R file let run!data set . Use help like ?gapminder.colours represent?size circles represent?describe relationship GDP per capita Life expectancy?","code":"\nlibrary(tidyverse)\nlibrary(gapminder)\n\ngapminder2007 <- gapminder %>% \n  filter(year == 2007)\n\nggplot(gapminder2007, aes(x = gdpPercap, y = lifeExp, color = continent, size = pop)) +\n  geom_point() +\n  scale_x_log10() +\n  xlab('GDP per capita') +\n  ylab('Life expectancy') +\n  labs(title = 'Gapminder data for the year 2007')"},{"path":"additional-exercises.html","id":"the-big-practical-importing-wrangling-summerizing-and-plotting","chapter":"C Additional exercises","heading":"C.2 The big practical: importing, wrangling, summerizing and plotting","text":"","code":""},{"path":"additional-exercises.html","id":"temperature-along-the-dutch-coast","chapter":"C Additional exercises","heading":"C.2.1 Temperature along the Dutch coast","text":"file Temperatur.csv book Zuur, Ieno, Meesters (2009) contains measurements temperature, salinity content chlorophyll 31 locations along Dutch coast. can download data set . data provided Dutch institute RIKZ (monitoring program MWTL: Monitoring Waterstaatkundige Toestand des Lands), measured 1990 2005 0 4 times per month depending season.Read file Temperatur.csv R.Convert column Date proper date format. Use library lubridate.Calculate number measurements, mean standard deviations temperature per monitoring station. Hint: use n() inside summarize() get number measurements.Calculate number measurements, mean standard deviations temperature per month.Plot mean monthly temperature line add standard deviation band around .Label axis appropriately.Save graph pdf file.","code":""},{"path":"additional-exercises.html","id":"temperature-along-the-dutch-coast-revisited","chapter":"C Additional exercises","heading":"C.2.2 Temperature along the Dutch coast, revisited","text":"Calculate monthly means standard deviations per monitoring station. Hint group_by(Station, Month).Plot means error band different plots. Hint: use facet_wrap()).Save graph pdf file.","code":""},{"path":"additional-exercises.html","id":"excel-data-turns-tidy","chapter":"C Additional exercises","heading":"C.2.3 Excel data turns tidy","text":"import tidy World Development Indicators data downloaded World Bank 2021-06-09 20 countries. extract data available.exercise show load excel data directly without converting .csv file. format data typical non-tidy one wrangle tidy tibble. file called Data_Extract_From_World_Development_Indicators.xlsx.goal exercise learn read data excel file using tidyverse functions. use library readxl function read_xlsx() reading files. Read help pages read_xlsx(), find set parameter reading particular table sheet correctly.Open excel sheet look data carefully. NAs coded? data sheet need read?Read excel file R. Call wdi.data set tidy. particular, year coded column name. column names contain year twice, number [YR NUMBER]. rename columns first.code mean? Read help pages functions rename_with(), str_sub() starts_with().Pivot data set tidy format: variables columns measurements rows. Use pivot_longer.code mean? Read help pages functions pivot_longer() .numeric().\nnecessary convert year .numeric()?Filter indicator GDP (current US$) plot data time series. Hint: can also filter indicator‚Äôs code; look excel file. Label axis appropriately.","code":"\nwdi <- wdi %>% \n  rename_with(.fn = function(x) str_sub(x, start = 1, end = 4), .cols = starts_with('20'))\nwdi <- wdi %>%\n  pivot_longer(names_to = 'year', values_to = 'indicator_value', cols = starts_with('20')) %>% \n  mutate(year = as.numeric(year))\n\nwdi"},{"path":"additional-exercises.html","id":"the-big-practical-statistical-inference","chapter":"C Additional exercises","heading":"C.3 The big practical: statistical inference","text":"","code":""},{"path":"additional-exercises.html","id":"species-richness-in-grasslands","chapter":"C Additional exercises","heading":"C.3.1 Species richness in grasslands","text":"work grassland species monitoring data Yellowstone National Park provided Zuur, Ieno, Meesters (2009) Sikkink et al. (2007). can download data set . researchers monitored changes grassland communities time related environmental factors. Biodiversity expressed number different species per site (variable R). Approximately 90 species identified 8 transects monitoring campaigns repeated every 4 10 years, resulting 58 observations. data saved file Vegetation2.xls.Read data explore structure. Describe type variables. type correspond expectation respective variable? Remember set name table sheet want read read_xls().Read data explore structure. Describe type variables. type correspond expectation respective variable? Remember set name table sheet want read read_xls().Short explorative data analysis: calculate number measurements, mean standard deviations species number R per transect.Short explorative data analysis: calculate number measurements, mean standard deviations species number R per transect.Plot species number versus variable BARESOIL (proportion bare soil). Colour dots transect. Hint: convert transect as_factor().Plot species number versus variable BARESOIL (proportion bare soil). Colour dots transect. Hint: convert transect as_factor().Add smoothing line without confidence band (geom_smooth(se = FALSE)) points independently transect. might want consult Section 4.2 book ggplot2 (Wickham 2020). Hint: set colour aes geom_point() instead ggplot().Add smoothing line without confidence band (geom_smooth(se = FALSE)) points independently transect. might want consult Section 4.2 book ggplot2 (Wickham 2020). Hint: set colour aes geom_point() instead ggplot().Add labels graph assign object.Add labels graph assign object.Plot species number time series transect. Add , points lines. size points reflect proportion bare soil. might want consult Section 12.1 book ggplot2 (Wickham 2020). Think set aesthetic size order scale points .Plot species number time series transect. Add , points lines. size points reflect proportion bare soil. might want consult Section 12.1 book ggplot2 (Wickham 2020). Think set aesthetic size order scale points .Add labels graph assign object.Add labels graph assign object.Put graphs side--side save pdf (ggsave()).Put graphs side--side save pdf (ggsave()).Calculate linear Pearson correlation coefficient species number proportion bare soil. Calculate 95% confidence interval. Use framework infer.Calculate linear Pearson correlation coefficient species number proportion bare soil. Calculate 95% confidence interval. Use framework infer.calculate 90% confidence interval instead 95% confidence interval, confidence interval increase decrease? ?calculate 90% confidence interval instead 95% confidence interval, confidence interval increase decrease? ?","code":""},{"path":"additional-exercises.html","id":"soil-compaction","chapter":"C Additional exercises","heading":"C.3.2 Soil compaction","text":"Heavy agricultural machines compact soil. randomized field trial, plots (variable plots) homogeneous agricultural field assigned randomly either control (control) treatment heavy agricultural machine used (compacted). Bulk density [g/cm¬≥] (mass dry soil divided soil volume) measured every plot. parameter soil structure can help spot soil compaction. data stored inbd_compaction.csv.Read data short explorative data analysis.bulk density increase due heavy machinery difference due chance? Use framework infer.Calculate effect size (difference means) 95% confidence interval.","code":""},{"path":"faq.html","id":"faq","chapter":"D Frequently and not-so-frequently asked questions","heading":"D Frequently and not-so-frequently asked questions","text":"","code":"\nlibrary(tidyverse)\nlibrary(palmerpenguins)"},{"path":"faq.html","id":"what-is-the-difference-between-double-and-single-quotes","chapter":"D Frequently and not-so-frequently asked questions","heading":"What is the difference between double \"\" and single '' quotes?","text":"difference. valid quote text/strings. Pay attention use quotes quotes like ‚Äúsolutions exercise ‚ÄòFind mean‚Äô.‚Äù quotes inside quotes must different (either \"\" outside ‚Äô‚Äô inside way round). However, may rendered differently plain R R Markdown e.g.¬†title.","code":"\nprint('I am a text.')## [1] \"I am a text.\"\nprint(\"So am I.\")## [1] \"So am I.\"\nprint(\"I am a 'quote' in a text.\")## [1] \"I am a 'quote' in a text.\"\nprint('So am \"I\", but not so nice looking.')## [1] \"So am \\\"I\\\", but not so nice looking.\""},{"path":"faq.html","id":"when-do-we-use-the-pipe-operator-and-when-the-plus-sign-to-connect-lines-of-code","chapter":"D Frequently and not-so-frequently asked questions","heading":"When do we use the pipe operator %>% and when the plus sign + to connect lines of code?","text":"pipe operator %>% used compose functions. Instead saving result every function passing result explicitly next function, can omit intermediate saving ‚Äúpipe‚Äù results :details pipes .plus sign + used operator ggplot2 , construct graph.","code":"\npenguins %>% \n  filter(species == 'Adelie') %>% \n  summarise(mean = mean(bill_length_mm, na.rm = TRUE))## # A tibble: 1 x 1\n##    mean\n##   <dbl>\n## 1  38.8\n# The same result, but not as tibble!\nfiltered_data <- filter(penguins, species == 'Adelie')\nmean(filtered_data$bill_length_mm, na.rm = TRUE)## [1] 38.79139\nggplot(data = penguins, aes(x = bill_length_mm, y = bill_depth_mm, col = species)) +\n  geom_point() +\n  geom_smooth(se = FALSE, method = lm)"},{"path":"literature-1.html","id":"literature-1","chapter":"Literature","heading":"Literature","text":"","code":""}]
